<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Fam Pract</journal-id><journal-id journal-id-type="iso-abbrev">BMC Fam Pract</journal-id><journal-title-group><journal-title>BMC Family Practice</journal-title></journal-title-group><issn pub-type="epub">1471-2296</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">27716161</article-id><article-id pub-id-type="pmc">5053347</article-id><article-id pub-id-type="publisher-id">538</article-id><article-id pub-id-type="doi">10.1186/s12875-016-0538-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Using program evaluation to support knowledge translation in an interprofessional primary care team: a case study</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Donnelly</surname><given-names>Catherine</given-names></name><address><email>catherine.donnelly@queensu.ca</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Shulha</surname><given-names>Lyn</given-names></name><address><email>lyn.shulha@queensu.ca</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Klinger</surname><given-names>Don</given-names></name><address><email>klingerd@queensu.ca</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Letts</surname><given-names>Lori</given-names></name><address><email>lettsl@mcmaster.ca</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label>School of Rehabilitation Therapy, Queen&#x02019;s University, 31 George Street, Kingston, ON K7L 4B4 Canada </aff><aff id="Aff2"><label>2</label>Faculty of Education, Queen&#x02019;s University, Duncan McArthur Hall, 511 Union Street, Kingston, ON K7M 5R7 Canada </aff><aff id="Aff3"><label>3</label>School of Rehabilitation Science, McMaster University, Room 403, 1400 Main St. W., Hamilton, ON L8S 1C7 Canada </aff></contrib-group><pub-date pub-type="epub"><day>6</day><month>10</month><year>2016</year></pub-date><pub-date pub-type="pmc-release"><day>6</day><month>10</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>17</volume><elocation-id>142</elocation-id><history><date date-type="received"><day>6</day><month>1</month><year>2016</year></date><date date-type="accepted"><day>23</day><month>9</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s). 2016</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>Evaluation is a fundamental component in building quality primary care and is ideally situated to support individual, team and organizational learning by offering an accessible form of participatory inquiry. The evaluation literature has begun to recognize the unique features of KT evaluations and has described attributes to consider when evaluating KT activities. While both disciplines have focused on the evaluation of KT activities neither has explored the role of evaluation in KT. The purpose of the paper is to examine how participation in program evaluation can support KT in a primary care setting.</p></sec><sec><title>Methods</title><p>A mixed methods case study design was used, where evaluation was conceptualized as a change process and intervention. A Memory Clinic at an interprofessional primary care clinic was the setting in which the study was conducted. An evaluation framework, Pathways of Influence provided the theoretical foundation to understand how program evaluation can facilitate the translation of knowledge at the level of the individual, inter-personal (Memory Clinic team) and the organization. Data collection included questionnaires, interviews, evaluation log and document analysis. Questionnaires and interviews were administered both before and after the evaluation: Pattern matching was used to analyze the data based on predetermined propositions.</p></sec><sec><title>Results</title><p>Individuals gained program knowledge that resulted in changes to both individual and program practices. One of the key themes was the importance clinicians placed on local, program based knowledge. The evaluation had less influence on the broader health organization.</p></sec><sec><title>Conclusions</title><p>Program evaluation facilitated individual, team and organizational learning. The use of evaluation to support KT is ideally suited to a primary care setting by offering relevant and applicable knowledge to primary care team members while being sensitive to local context.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (doi:10.1186/s12875-016-0538-4) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Interdisciplinary health team</kwd><kwd>Primary health care</kwd><kwd>Knowledge translation</kwd><kwd>Integrated knowledge translation</kwd><kwd>Program evaluation</kwd><kwd>Case study</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2016</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>It has been recognized that primary care has unique issues related to knowledge translation (KT). As the first point of contact with the health care system, health issues may not be clearly articulated and broad health services are provided to a range of conditions across the lifespan [<xref ref-type="bibr" rid="CR1">1</xref>]. Primary care clinicians have been found to rely heavily on clinical practice guidelines however these are primarily developed for single diseases, &#x0201c;filtered by specialists&#x0201d; making them difficult to apply to the primary care setting where patients often present with multiple chronic conditions [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Menar and colleagues explored KT and primary care, and stressed the importance of adopting an integrated knowledge translation (IKT) approach within primary care as a way to actively engage primary care providers in the research process and support the production of contextually relevant knowledge [<xref ref-type="bibr" rid="CR1">1</xref>]. Integrated knowledge translation (IKT) is the term used to describe the active collaboration between researchers and research users in all parts of the research process [<xref ref-type="bibr" rid="CR3">3</xref>].</p><p>The Knowledge to Action Framework is a model for conceptualizing the movement of knowledge into practice and has been adopted by the Canadian Institute of Health Research (CIHR) [<xref ref-type="bibr" rid="CR3">3</xref>]. The KTA framework is divided into two components: knowledge creation and action. The Action phase represents activities used to assist in the application of knowledge, with eight specific processes including the evaluation of outcomes. As the framework highlights, both the KT and program evaluation literature have focused on the evaluation of KT intervention [<xref ref-type="bibr" rid="CR4">4</xref>&#x02013;<xref ref-type="bibr" rid="CR7">7</xref>] but neither has explored how engaging in a program evaluation can support KT.</p><sec id="Sec2"><title>Program evaluation and knowledge translation</title><p>Program evaluation can be differentiated from research by its central focus on practice driven questions and goals of program and organizational improvement [<xref ref-type="bibr" rid="CR8">8</xref>]. In primary care terms such as continuous quality improvement (CQI) and quality frameworks are often used when referring to processes that ensure quality care and outcomes. Program evaluation has many similarities to CQI, and some view them within a continuum of approaches to support organizations and program delivery. CQI is specifically focused on processes and systems, and focuses on ongoing improvements to deliver quality outcomes [<xref ref-type="bibr" rid="CR9">9</xref>]. Program evaluation on the other hand is a broader concept and includes a wide range of approaches (e.g. summative, formative) and whose goal is ultimately aimed at determining the merit and worth of programs [<xref ref-type="bibr" rid="CR10">10</xref>].</p></sec><sec id="Sec3"><title>Participatory inquiry and evaluation</title><p>In the many forms of program evaluation, stakeholder participation is purposefully cultivated to facilitate learning and knowledge building [<xref ref-type="bibr" rid="CR11">11</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref>]. These practices reflect early and ongoing research on how participation enhances relevancy and therefore stakeholder use of evaluations [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. While IKT is often described as a process akin to participatory research, evaluation also seeks to engage participants in the evaluation process [<xref ref-type="bibr" rid="CR12">12</xref>]. Given the emphasis on both KT and quality improvement initiatives in primary care [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>] understanding evaluation&#x02019;s role in KT can provide valuable insights into how evaluation can be structured to support both the creation of knowledge that addresses local practice needs and the application of this knowledge to enhance practice outcomes.</p><p>Evaluation theorists Henry and Mark [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] offer a framework that can explore how evaluation can be used to support KT. Mark and Henry&#x02019;s framework examines the influence of evaluation at the level of the individual, interpersonal and organization, where evaluation is conceptualized as change process. Viewing evaluation as a change process considers the engagement in the evaluation as a process that supports the application of new knowledge and research to practice. A recent systematic review of KT interventions in primary care highlighted the need to consider context and ensure interventions are applicable to the specific primary care settings [<xref ref-type="bibr" rid="CR20">20</xref>]. Given evaluations focus on program-based questions, evaluation it ideally situated to be considered an approach that can support the uptake of research to practice in primary care. To date there has been no exploration of how evaluation can be used to support KT in primary care [<xref ref-type="bibr" rid="CR20">20</xref>]. This study seeks to answer the following questions: How does participation in an evaluation influence a) individual members in the program, b) interpersonal behaviours in the program, and c) the broader primary care organization.</p></sec></sec><sec id="Sec4"><title>Methods</title><p>A prospective, multiple methods case study design was employed [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. Case study research focuses on understanding a given phenomenon in a real-life environment and involves the collection of detailed information using a variety of data sources [<xref ref-type="bibr" rid="CR22">22</xref>]. Evaluation has been used to examine the impact of KT activities, but there have been no records of how program evaluation as a process can be formally used to support KT in primary care. A case study design offered a methodology to gain an in-depth understanding of if, how, and why evaluation can be used for KT. The Pathways of Influence [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] was the theoretical framework used to demonstrate how evaluation can support both knowledge creation and its application to practice during one evaluation in a primary care setting.</p><p>Ethics approval was provided by the Queen&#x02019;s University Health Sciences and Affiliated Teaching Hospitals Research Ethics Board (HSREB) (approval #6006766). Each participant provided written and informed consent to participate in the study and were made aware that results from the study would be disseminated and published.</p><sec id="Sec5"><title>Case study context</title><p>An evaluation of a Memory Clinic at an interprofessional primary care organization in the province of Ontario, Canada provided the context for the study. The Memory Clinic was part of an informal group of primary-care based memory clinics within the province of Ontario, Canada. Prior to the implementation of the Memory Clinic, all members completed a formal training to gain knowledge in the area of dementia. With long wait times to access specialist services, the objectives of the Memory Clinic were to facilitate the early diagnosis of memory disorders and provide community and caregiver support in a primary care context. Patients and caregivers attended a 2-hour interprofessional assessment. Following the assessment, a diagnosis was made and an individual care plan was provided. The Memory Clinic was offered on a monthly basis to patients with memory impairments and their families and was delivered by an interprofessional team of health providers including two physicians, two nurses, an occupational therapist, a social worker, a community pharmacist and an Alzheimer Society representative [<xref ref-type="bibr" rid="CR23">23</xref>].</p></sec><sec id="Sec6"><title>Evaluation approach</title><p>The evaluation used a participatory approach [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR24">24</xref>] and was also informed by efforts to support a knowledge translation approach to evaluation [<xref ref-type="bibr" rid="CR25">25</xref>]. <italic>The Program Evaluation Standards</italic> [<xref ref-type="bibr" rid="CR10">10</xref>] provided a foundation to conduct an ethical and quality evaluation. The intention of bringing these approaches together was to orchestrate a quality and collaborative evaluation that facilitated the development and refinement of the Memory Clinic through the ongoing translation of research and evaluation data. The study used a novel approach to evaluation, developed specifically to support KT in primary care, which was termed a KT-informed evaluation [<xref ref-type="bibr" rid="CR25">25</xref>]. The KT-informed evaluation was designed to be intentional in facilitating the application of emerging evaluation knowledge into practice and attended to the empirical evidence (original studies or synthesized knowledge) that grounded the program and the clinicians within the program. The evaluation was cognizant of how empirical and formalized knowledge informed each phase of the evaluation: (a) ensuring evaluation questions were informed both by context and external evidence, and (b) that emerging and final findings were considered in light of current research. Three intentional activities were included in this approach; weekly e-newsletters, monthly Evaluation Process Meeting to review and discuss emerging findings and an evaluator presence in the program. A detailed description of this approach has been described in the literature [<xref ref-type="bibr" rid="CR25">25</xref>].</p><sec id="Sec7"><title>Participatory evaluation</title><p>This evaluation was designed to support KT by adopting a participatory approach. Participatory evaluation involves some degree of collaboration between those conducting the evaluation and the stakeholders [<xref ref-type="bibr" rid="CR11">11</xref>].</p><p>The extent to which an evaluation is participatory can be determined by mapping the evaluation process onto three dimensions of collaborative inquiry [<xref ref-type="bibr" rid="CR11">11</xref>]; control of technical evaluation decisions, diversity of stakeholders selected for participation and depth of participation. Each dimension was considered in the evaluation design. In this evaluation, the evaluator ultimately led the technical evaluation decisions, with strong input obtained from program members at all stages throughout the evaluation. All organizational stakeholders were represented in the Evaluation Committee, whose membership included Memory Clinic clinicians, along with the Alzheimer society representative and the organization&#x02019;s Executive Director; providing clinical, community and administrative perspectives. Members participated in the evaluation through monthly Evaluation Process Meetings and email communication; offering feedback and input into all aspects of the evaluation including the design, interpretation of data and translation of findings into the program.</p></sec></sec><sec id="Sec8"><title>Participants</title><p>As the goal of this paper is to examine how evaluation can support KT, the evaluation of the Memory Clinic was the focus of the case study. All members of the Memory Clinic sat on the Memory Clinic&#x02019;s Evaluation Committee and each member was invited to participate in the study. Six of the seven original Evaluation Committee members agreed to participate at the outset of the study. One member who did not participate at intake agreed to do so at follow-up. Due to incomplete data, questionnaires from the seventh participant were not included in the analysis, however a follow-up interview was conducted and included in the study. Two additional members joined the Memory Clinic over the course of the 8-month evaluation, but were not included in the sample.</p></sec><sec id="Sec9"><title>Data collection</title><p>Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> provides a summary of the overall data collection tools and timing of administration. Multiple sources of data were collected over 11-months, at three points in time.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Data collection timeline</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Data collection</th><th>Pre</th><th>Post</th><th>Follow-up</th></tr></thead><tbody><tr><td rowspan="2">Edmonton research orientation scale</td><td>&#x02022;</td><td>&#x02022;</td><td/></tr><tr><td>&#x02022;</td><td>&#x02022;</td><td/></tr><tr><td>Memory clinic knowledge questionnaire</td><td>&#x02022;</td><td>&#x02022;</td><td/></tr><tr><td>Interview &#x02013; understanding individual and interactive levels</td><td>&#x02022;</td><td>&#x02022;</td><td/></tr><tr><td>Interview &#x02013; understanding the collective level</td><td/><td/><td>&#x02022;</td></tr><tr><td>Program documents</td><td colspan="3">
<inline-graphic xlink:href="12875_2016_538_Figa_HTML.gif" id="d30e570"/>
</td></tr><tr><td>Evaluation log</td><td colspan="3">
<inline-graphic xlink:href="12875_2016_538_Figb_HTML.gif" id="d30e580"/>
</td></tr></tbody></table></table-wrap>
</p><p>All questionnaires were printed and paper copies were provided to participants, along with a self-addressed, stamped envelope. Each participant completed the questionnaires individually at their convenience and returned these via mail, to the primary author.</p><sec id="Sec10"><title>Edmonton research orientation survey</title><p>The Edmonton Research Orientation Survey [<xref ref-type="bibr" rid="CR26">26</xref>] is a self-report tool that asks participants about their attitudes toward research and about their potential to use research findings. The assessment contains 38 items with four subscales. The items are scored on a 5-point Likert scale from strongly disagree to strongly agree, with higher scores indicating a more positive research orientation. The Edmonton Research Orientation Survey (EROS) was developed in the context of rehabilitation and has been used across health disciplines, including nursing [<xref ref-type="bibr" rid="CR27">27</xref>&#x02013;<xref ref-type="bibr" rid="CR29">29</xref>]. The EROS has demonstrated internal consistency reliability (Cronbach&#x02019;s alpha =0.83&#x02013;0.89) and content and concurrent validity in rehabilitation, nursing and general hospital settings [<xref ref-type="bibr" rid="CR30">30</xref>]. This is the first known use within a primary care setting.</p></sec><sec id="Sec11"><title>Collaborative practice assessment tool</title><p>The Collaborative Practice Assessment Tool (CPAT) is a self-report questionnaire designed to assess individual team members&#x02019; perceptions of collaborative practice. The CPAT contains 56 items across eight domains that have been identified in the literature as relating to interprofessional collaborative practice. Results of two pilot tests have demonstrated that the CPAT is a valid and reliable tool [<xref ref-type="bibr" rid="CR31">31</xref>].</p></sec><sec id="Sec12"><title>Memory clinical knowledge questionnaire</title><p>The Memory Clinical Knowledge Questionnaire (MCK) was developed for this study by the authors to assess participant&#x02019;s knowledge about assessment and intervention practices related to memory. No similar measures were found in the literature. The MCK questionnaire consisted of 6 close-ended and 3 open-ended questions asking respondents about their confidence and breadth of knowledge related to memory disorders as well as memory assessments and interventions currently used. See Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Memory Clinic Knowledge Questionnaire.</p></sec><sec id="Sec13"><title>Interviews</title><p>Fourteen interviews were conducted with participants from the Evaluation Committee. Interviews lasted between 20 and 60&#x000a0;min. Questions were developed by the research team and guided by Mark and Henry&#x02019;s Pathways of Influence framework [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] Interviews were conducted with all participants before and after the evaluation and held in a quiet, private office. Participants were asked how the evaluation influenced individuals&#x02019; clinical practices, knowledge and attitudes. Questions were also asked about how the evaluation influenced interactions with team members, patients and other knowledge networks. Three month follow-up interviews were conducted with two individuals identified to have influence at the level of the broader primary care organization.</p></sec><sec id="Sec14"><title>Evaluation log</title><p>An evaluation log was maintained by the primary author (CD), who was also the primary evaluator of the program. Entries were made following interactions with the Memory Clinic to document evaluation processes and knowledge translation activities. All evaluation log entries followed the Objective, Reflective, Interpretive, and Decisional. (ORID) framework, a method for focused discussion presented in the business literature [<xref ref-type="bibr" rid="CR32">32</xref>] that has been adapted to guide reflective journaling [<xref ref-type="bibr" rid="CR33">33</xref>]. Each entry attended to the four ORID stages and included: (a) a description of the knowledge translation event including date and nature of the event, (b) evaluator reaction to the event, (c) interpretation and analysis of the event and (d) a description of how the KT event would guide future KT events. Log entries were entered directly and sequentially into a word processing document.</p></sec><sec id="Sec15"><title>Program documents</title><p>Program documents included patient handouts, educational materials, program meeting minutes and final evaluation report.</p></sec></sec><sec id="Sec16"><title>Data analyses</title><p>Pattern matching was used as the overall analytic strategy. This approach &#x0201c;compares an empirically based pattern with a predicted one&#x0201d; [<xref ref-type="bibr" rid="CR21">21</xref>], where propositions are developed prior to data collection in order to identify a predicted pattern of variables. Propositions for this study were derived from the theoretical framework of Henry and Mark [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] and informed by the knowledge translation literature.<list list-type="order"><list-item><p>Individuals who engage in a KT-informed evaluation will:<list list-type="alpha-lower"><list-item><p>have a greater knowledge of assessments and interventions of memory disorders.</p></list-item><list-item><p>have a positive attitude towards research and evaluation.</p></list-item><list-item><p>refine clinical practices and process based on empirical evidence and evaluation results and processes.</p></list-item></list>
</p></list-item><list-item><p>Being engaged in a KT-informed evaluation will support program interactions and build knowledge translation capacity within the team.</p></list-item><list-item><p>The primary care organization will develop structures and practices to ensure data and evidence inform health service delivery and program development (i.e. use of electronic medical record to collect and use patient data).</p></list-item></list>
</p><p>Data were entered into an excel spreadsheet and tables were used to visually examine the data. Descriptive analyses were performed on the EROS [<xref ref-type="bibr" rid="CR26">26</xref>] and CPAT [<xref ref-type="bibr" rid="CR31">31</xref>]. Item averages were calculated for EROS [<xref ref-type="bibr" rid="CR26">26</xref>] due to missing data, and subscale and total score averages were calculated for the CPAT [<xref ref-type="bibr" rid="CR31">31</xref>]. Given the small sample size statistical significance was not calculated for either the EROS or CPAT. Qualitative interview data were digitally recorded and transcribed verbatim by a research assistant. Atlas ti, a qualitative data analysis and research software, was used to code data and identify themes. The primary author read all transcripts and a preliminary coding table was established. Transcripts were re-read, resulting in the collapse of ten codes, due to overlap. In total 20 codes were included in the final coding table from which seven broad themes emerged. Because of the small number of participants, quotes included in the manuscript are not identified by health profession.</p><p>A number of strategies were used to establish trustworthiness [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR35">35</xref>]. Two transcripts were read and independently coded by a second investigator (LS) using the final coding structure. A second strategy to establish trustworthiness involved member checking. Participants were provided with interview summaries and asked to contact the primary author if any errors were noted, or if additional information should be included. None of the participants reported any errors or provided further information.</p><p>A third strategy involved triangulation of data methods, sources and investigators. The study included a number of data methods including interviews, questionnaires and program documents. Each contributed to the understanding of the influence of evaluation and how it can be used as a mechanism for IKT. Participants included members from a range of disciplines, who were both internal and external to the organization to provide different perspectives and experiences of participating in the evaluation. Finally, the investigation team was made up of two occupational therapists (CD, LL), one evaluation researcher and practitioner (LS), and one educational researcher (DK). The diversity of the team brought unique perspectives to the design, implementation and analyses and grounded the study in both research and practice.</p></sec></sec><sec id="Sec17"><title>Results</title><p>There were a total of six members on the Evaluation Committee. Two members had worked on an interdisciplinary team for over 10&#x000a0;years, two members had worked between 5 and 10&#x000a0;years on an interprofessional team and two had worked on an interprofessional team for 1&#x000a0;year or less. The evaluation was found to influence the individuals, team and broader organizations in ways that were both intended and unintended. Seven overall themes were identified across the individual, interpersonal and collective levels. See Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> for an overview of the themes.<fig id="Fig1"><label>Fig. 1</label><caption><p>Evaluation for knowledge translation: themes and subthemes</p></caption><graphic xlink:href="12875_2016_538_Fig1_HTML" id="MO1"/></fig>
</p><sec id="Sec18"><title>Influence on the individual</title><sec id="Sec19"><title>Local knowledge</title><p>Individuals obtained knowledge from a range of both formal and informal sources. The sources of knowledge evolved over the course of the evaluation. Pre-evaluation questionnaires identified resources found within the Memory Clinic Training Manual as the most frequent source of formalized knowledge. Following the evaluation however, the weekly evaluation e-newsletter was identified as the source most frequently accessed for information. Virtual practice networks and online materials also provided important resources for participants.</p><p>Team members were a critical source of knowledge. During post-evaluation interviews, all but one of the members identified the team as the first place they would turn to for information. In addition to the immediate team, individuals from the Memory Clinic training team were also identified as key sources of information. In these situations, communication was primarily between similar disciplines, for example the nurse at the Memory Clinic would contact the nurse at the training site. Overall, when knowledge was local and research was considered within context it was seen as relevant and directly applicable. &#x0201c;I want the local, and the reliable [information], and a study from Toronto, from someone with who knows what credentials, isn&#x02019;t any help to my clients that are here right now&#x0201d; (FpP7:8:46).</p><p>The intentional knowledge translation strategies used during the course of the evaluation [<xref ref-type="bibr" rid="CR10">10</xref>], coupled with evaluation processes and emerging results provided the team with local practice-based knowledge.</p><p>&#x0201c;The evaluation informed my practice for sure, because not just the evidence-based approach and articles that [the evaluator] was sending, but also we have program objectives and knowing what our focus was informed me as well&#x0201d; (PostP1:1:4).</p></sec><sec id="Sec20"><title>Orientation to practice based inquiry</title><p>While a KT-informed evaluation sought to sensitize individuals to research the Edmonton Research Orientation Scale (EROS) [<xref ref-type="bibr" rid="CR26">26</xref>] did not demonstrate any shift in orientation towards research. EROS subscale scores could not be calculated due to missing data on a number of items; most notably within the Involvement in Research and Evidence Based Practice subscales. As a result the average rating per item was calculated (see Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). Item averages remained essentially the same across all four subscales, with two subscales slightly lower at follow-up and one slightly higher, suggesting the evaluation had minimal impact on the individual&#x02019;s orientation towards research. Knowledge related to five aspects of research increased slightly from pre-to-post evaluation. There was no change in time spent reading or participating in research or research related activities.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Edmonton Research Orientation Scale (EROS)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>EROS subscale</th><th>Pre-evaluation (<italic>n</italic>&#x02009;=&#x02009;5)<sup>a</sup>
</th><th>Standard deviation</th><th>Post-evaluation (<italic>n</italic>&#x02009;=&#x02009;6)<sup>a</sup>
</th><th>Standard deviation</th></tr></thead><tbody><tr><td>Valuing Research</td><td>3.7</td><td>0.7</td><td>3.7</td><td>0.6</td></tr><tr><td>Research Involvement</td><td>2.4</td><td>0.9</td><td>2.2</td><td>0.6</td></tr><tr><td>Being on the Leading Edge</td><td>3.8</td><td>0.8</td><td>3.9</td><td>0.5</td></tr><tr><td>Evidence Based Practice</td><td>3.7</td><td>0.6</td><td>3.5</td><td>0.7</td></tr><tr><td>Total:</td><td>3.4</td><td>0.9</td><td>3.3</td><td>0.9</td></tr><tr><td>Understanding Research Design</td><td>2.6</td><td>1.5</td><td>2.8</td><td>1.2</td></tr><tr><td>Statistics</td><td>2.6</td><td>1.1</td><td>2.8</td><td>1.2</td></tr><tr><td>Research articles in journals</td><td>3.4</td><td>1.1</td><td>3.7</td><td>0.9</td></tr><tr><td>Grant application procedures</td><td>1.8</td><td>0.8</td><td>1.8</td><td>0.9</td></tr><tr><td>Ethical review procedures</td><td>1.8</td><td>1.2</td><td>2.0</td><td>1.1</td></tr></tbody></table><table-wrap-foot><p>
<sup>a</sup>item averages on a 5-point scale</p></table-wrap-foot></table-wrap>
</p><p>While general research orientation, as measured by the EROS [<xref ref-type="bibr" rid="CR26">26</xref>], remained unchanged, interview data highlighted the role evaluation played in making research more accessible.</p><p>&#x0201c;I think [the evaluation] humanized the idea of research instead of it being all the research out there that I am not part of, so this brought it into my realm of general practice and day to day practice&#x0201d; (postP4:4:1).</p><p>The evaluation served to orient clinicians to practice based inquiry, bridging the research-practice divide. &#x0201c;It seems so practical, it just seems so natural and I always saw research as more academic&#x0201d; (postP4:18:48). Through the evaluator&#x02019;s presence and engagement in the evaluation, clinicians not only gained knowledge about the process of conducting an evaluation, but more specifically how knowledge created through evaluation translated to practice. &#x0201c;Having [the evaluator] so involved helped us learn more about what an evaluation is, what it looks like, how it works into the day-to-day stuff we are learning, and how it translates&#x0201d; (postP1:42:92).</p><p>The KT-informed evaluation sought to model sustainable practice based inquiry. While the evaluation did not appear to influence individuals&#x02019; orientation or attitude to research broadly, it supported an orientation to local practice-based inquiry and knowledge.</p></sec><sec id="Sec21"><title>Shaping clinical practice</title><p>Changes to clinical practice were documented over the course of the evaluation and were related to both the evaluation processes and results. Not only did individuals gain knowledge during the evaluation they were receptive to making changes to practice as a result of this knowledge. &#x0201c;We have to be open to change what we find does need to be changed&#x02026;you have to be willing to change&#x0201d; (postP3:6:30). Over the course of the 8-month evaluation a number of refinements were made to the assessment and intervention practices and Memory Clinic processes. Refer to Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref> for description of changes that were made and how the evaluation process linked to these changes.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Influence on clinical activities and processes</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2">Program enhancements and modifications made throughout evaluation</th></tr></thead><tbody><tr><td>Clinic assessments</td><td>Evaluation activities implemented that supported program enhancements</td></tr><tr><td rowspan="3">&#x02003;1. Addition of a gait assessment into the assessment protocol.</td><td>Memory clinic network conference</td></tr><tr><td>Weekly evaluation update - E-newsletter</td></tr><tr><td>Memory clinic process meeting</td></tr><tr><td rowspan="2">&#x02003;2. Addition of vital statistics into the assessment protocol.</td><td>Memory clinic network conference</td></tr><tr><td>Memory clinic process meeting</td></tr><tr><td rowspan="2">&#x02003;3. Additional of &#x0201c;Since we last saw you&#x0201d;, an assessment of community supports into the assessment protocol.</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; chart audits, patient and caregiver feedback surveys</td></tr><tr><td>Clinic intervention/follow-up activities</td><td>Evaluation activities implemented that supported program enhancements</td></tr><tr><td rowspan="2">&#x02003;1. Enhancement of educational materials (driving, enhanced mail-out package, educational binder)</td><td>Evaluation results - patient and caregiver feedback surveys</td></tr><tr><td>Weekly evaluation update - E-newsletter</td></tr><tr><td rowspan="2">&#x02003;2. Patient action plans</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; patient and caregiver feedback surveys</td></tr><tr><td rowspan="2">&#x02003;3. Patient/caregiver Workshop: brain gym</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; patient and caregiver feedback surveys</td></tr><tr><td rowspan="2">&#x02003;4. Patient/caregiver workshop: dementia and diabetes</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; patient and caregiver feedback surveys</td></tr><tr><td>Memory clinic processes</td><td>Evaluation activities implemented that supported program enhancements</td></tr><tr><td rowspan="2">&#x02003;1. Patient services coordinator: new title and timing of introduction</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; patient and caregiver feedback surveys</td></tr><tr><td>&#x02003;2. Stopping of evaluation process meetings</td><td>Evaluation process meeting</td></tr><tr><td rowspan="2">&#x02003;4. Assessment summary forms (Under consideration at end of evaluation.</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; chart review</td></tr><tr><td rowspan="2">&#x02003;5. Timing of patient/family education</td><td>Evaluation process meeting</td></tr><tr><td>Evaluation results &#x02013; patient and caregiver feedback surveys</td></tr><tr><td>&#x02003;6. Patient chart scanned into EMR</td><td>Evaluation results - physician feedback survey</td></tr></tbody></table></table-wrap>
</p><p>Three elements of the evaluation were seen to influence clinical practice; knowledge gained from engagement in the evaluation process, empirical evidence provided during the evaluation, and emerging evaluation results. Participant engagement in evaluation created a culture of learning and laid the foundation for knowledge translation. &#x0201c;When you see [the evaluation] and you&#x02019;re involved in it, and doing it, it&#x02019;s more hands on, it&#x02019;s more practical, it&#x02019;s apt to be more useful&#x0201d; (postP3:25). Similarly, evaluator engagement in the program supported knowledge translation.</p><p>&#x0201c;Having [evaluator] so involved has helped us learn about what an evaluation is and what it looks like, how it works into the day to day [information] we are learning and how it translates&#x02026;[evaluator] being involved really helped us getting it and understanding it (postP1:42:92).</p><p>Fundamentally, the knowledge translation focus of the evaluation sought to support patient care &#x0201c;this evaluation&#x02026;it is being done to produce better quality patient care and I think we all know that now&#x0201d; (postP1:41:90). Weekly e-newsletters, offered a source of empirical evidence upon which practitioners grounded their assessment practices.</p><p>Just knowing what is happening&#x02026;the updates and some of the research articles&#x02026;that guides me and that started the gait [assessment] process, so it helped us if we got stuck in our ways and gave us new ideas (postP2:2:4).</p><p>Interventions were also supported by the intentional knowledge translation activities of the evaluation.</p><p>What we developed here was a [patient education] binder&#x02026;some tips about eating and exercise and all of that was pulled from the evidence based practice stuff I pulled from Dr. [X,] or things [the evaluator] sent us or things that the team provided that they found to be helpful (postP1:35:66).</p><p>The Memory Clinic team was particularly receptive to emerging data derived from patient and caregivers, which in turn had a strong influence on Memory Clinic processes and clinical practices. The patient focus was seen at the clinical level and many of the clinicians identified that patient interactions was the element of clinical practice most influenced by the emerging evaluation data. &#x0201c;I have learned to ask more open ended questions and dig deeper and get better detailed answers&#x0201d; (postP5:6:24). Another clinician reported &#x0201c;it has changed the way I do the testing and assessments, building that relationship&#x0201d; (postP6:9:24).</p><p>The Memory Clinic was part of a larger network of clinics and receiving the ongoing feedback from the emerging evaluation also gave individuals the confidence and the structure to refine their practice. It also gave clinicians confidence in their own clinical practice.</p><p>We kept refining the process based on the feedback, based on [the evaluation], refined it, refined it, refined it, and the whole collection of information from the patients, and how we recognize that, and how we record that, and access it later. We are more confident (postP4:21:56).</p><p>Feedback also supported changes to program delivery. &#x0201c;So, once we got that feedback&#x02026; that changed how we were thinking about educating people and the timing of the education&#x0201d; (postP1:36:68). Changes were also made to administrative processes based on feedback &#x0201c;We kept changing our forms and making them better&#x0201d; (postP2:10:28).</p><p>Participants reported an increased use of memory related assessments and interventions over the course of the evaluation. Individuals (<italic>n</italic>&#x02009;=&#x02009;5) reported using an average of 3 assessments (range1-5) on the pre-evaluation Memory Disorders Knowledge Questionnaire, compared with an average of 8 (range 4 to 17) assessments after the evaluation. The same trend was observed for interventions. Individuals (<italic>n</italic>&#x02009;=&#x02009;5) reported using an average of 2 (range 0 to 3) interventions when working with individuals with memory disorders before the evaluation and an average of 5 (range 3 to 8) interventions on the post-evaluation questionnaire. Referral to community supports was not identified as an intervention strategy on the pre-evaluation questionnaire, whereas all but one of the respondents on the post-evaluation questionnaire reported accessing community resources for patients and their families/caregivers.</p></sec></sec><sec id="Sec22"><title>Influence on the interpersonal</title><sec id="Sec23"><title>Roadmap for sustainability</title><p>With the exception of the early addition of a community pharmacist and physician, team membership remained stable over the course of the 8-month evaluation. However, as the evaluation was concluding the team underwent substantial personnel changes, including two members going on maternity leave, the addition of another pharmacist and two members leaving the primary care clinic; including the Executive Director. Only 1&#x000a0;month after the evaluation was completed, five new members had joined the team, representing a 62 % turnover rate.</p><p>As membership changed, so too did the teams knowledge that was co-created over the course of evaluation. Prior to the changes in personnel &#x0201c;We were all sitting in that room together, so I know that information that I got from you&#x02026;and you heard what I got&#x02026;we all heard&#x0201d; (fpP7:19:104). However, as new members entered &#x0201c;we don&#x02019;t really know what everyone else [knew]&#x0201d; (fpP7:19:100).</p><p>Despite new membership there was a commitment to sustaining the team&#x02019;s clinical knowledge base and building on the evaluation &#x0201c;we want to keep learning&#x0201d; (postP5:11:63). One of the original team members informally took on the responsibility of creating strategies and mechanisms to transfer knowledge to the new members, passing along &#x0201c;the essential building blocks of this clinic and [handing] them out to everyone&#x02026;so you have got a pillar who continues&#x0201d; (fpP4:4:26). Strategies included laminating summaries of memory disorder assessments and the development of a memory disorder clinical reasoning flowchart.</p><p>Supporting the team&#x02019;s informal KT leader, were formalized tools that provided a roadmap for the team. &#x0201c;None of us could do this alone, so many people have given us the tools&#x02026;[XX] just making sure the tools are handed down in their original, authentic form&#x0201d; (fpP4:6:54). There were clear supports to translate clinical knowledge however there was less evidence that structures were in place to support ongoing learning through evaluation. On one hand the evaluation was seen as one tool within the KT toolkit, offering processes to both collect data and provide ongoing feedback to the team. &#x0201c;[the evaluator] has given us clinical applications that actually will guide what we do&#x0201d; (fpP4:7:66). On the other hand, no formal procedures were in place to facilitate data collection and reporting. Unlike with the clinical knowledge, no team member had informally stepped into the role to translation evaluation knowledge or practices.</p></sec><sec id="Sec24"><title>Evaluation: a common ground</title><p>The evaluation of the Memory Clinic began during the early formation of the team, and prior to the start of the implementation of the clinic. The evaluation provided a common ground for the team members, all of whom came from different disciplinary backgrounds. Through the participatory processes of the evaluation, the team developed program goals and objectives. This process had a number of benefits to the team. First it encouraged the team to shed their disciplinary focus.</p><p>&#x0201c;Hearing what kind of things people said for goals, it was not what I expected. From the doctor, I would have expected it would be to give a clearer diagnosis. But instead it was to support the client and the caregiver&#x0201d; (postP2:28:77).</p><p>Second, the program goals and objectives served to centre the team and pull members towards a common focus. &#x0201c;Those first few meetings trying to take the objectives and keep them in mind&#x02026;and just to have clear objectives that we shared&#x0201d; (postP4:21:56).</p><p>The emerging evaluation findings offered program based knowledge, which crossed disciplinary boundaries. Team members were required to make sense of how the information influenced the team as a whole and then their individual practices. One team member reflected on how the emerging evaluation results heightened her awareness of the need to strengthen collaborative practice.</p><p>&#x0201c;It heightened my awareness of caregiver burnout, the need for the services here&#x02026; the need to find strong partnerships especially with the Alzheimer&#x02019;s society and working side by side&#x02026;and somehow being more mindful of collaborative practice&#x0201d; (postP1:11:28).</p><p>The team viewed the Memory Clinic as a model of interprofessional collaboration in the primary care clinic. &#x0201c;It would be great if our other programs were run like that&#x0201d; (postP6:12:30). Because of the commitment to the team, there was also a commitment to the evaluation.</p><p>&#x0201c;I think the fact that the Memory Clinic is new and an exemplar of interprofessional collaboration within the [primary care clinic] creates a deeper commitment to both the evaluation and openness to dementia research and networks&#x0201d; (Evaluation log, September 13, 2012).</p><p>Results of the Collaborative Practice Assessment Tool (CPAT) [<xref ref-type="bibr" rid="CR31">31</xref>] further demonstrated the team&#x02019;s collaboration. All domains of the CPAT scores increased over the course of the evaluation, with a total CPAT score before the evaluation of 321 and 362 following the evaluation (Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref>). <table-wrap id="Tab4"><label>Table 4</label><caption><p>Collaborative Practice Assessment Tool (CPAT)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>CPAT subscale (total subscale score)</th><th>Pre-evaluation (<italic>n</italic>&#x02009;=&#x02009;6)</th><th>Standard deviation</th><th>Post-evaluation (<italic>n</italic>&#x02009;=&#x02009;6)</th><th>Standard deviation</th></tr></thead><tbody><tr><td>Mission (56)</td><td>49</td><td>3.5</td><td>52</td><td>2.8</td></tr><tr><td>Relationships (56)</td><td>52</td><td>3.6</td><td>55</td><td>2.6</td></tr><tr><td>Leadership (63)</td><td>50</td><td>5.7</td><td>55</td><td>9.0</td></tr><tr><td>Roles (70)</td><td>58</td><td>9.5</td><td>64</td><td>8.7</td></tr><tr><td>Communication (48)</td><td>34</td><td>5.5</td><td>41</td><td>4.2</td></tr><tr><td>Community (28)</td><td>24</td><td>1.7</td><td>27</td><td>2.0</td></tr><tr><td>Conflict (42)</td><td>26</td><td>2.7</td><td>37</td><td>4.4</td></tr><tr><td>Patient involvement (35)</td><td>28</td><td>4.1</td><td>31</td><td>5.0</td></tr><tr><td>Total (398)</td><td>321</td><td>20.5</td><td>362</td><td>20.8</td></tr></tbody></table></table-wrap>
</p><p>Conflict and communication were the two domains that demonstrated the greatest change scores. The results of the opened ended questions reiterated communication as a team strength as well as the establishment of a culture of collaboration, involving trust, respect and openness to others ideas. The team created a term to capture the collaborative spirit they felt. &#x0201c;Teamy, we call it&#x0201d; (fpP4:).</p></sec></sec><sec id="Sec25"><title>Influence on the collective</title><sec id="Sec26"><title>It will&#x02026; in time</title><p>There was little evidence to suggest that the primary care organization in which the Memory Clinic was situated was influenced by the evaluation. While the evaluation was seen as foundational to the development of the Memory Clinic, the influence on the primary care clinic was not felt. &#x0201c;I just don&#x02019;t know if it has trickled down to the broader health team&#x02026;I think it will in time, and I think that as other programs evolve. I think it is foundational&#x0201d; (fpP3:26:118). No formal evaluation structures were in place for any other programs and there were no reported plans to formally introduce evaluation to other programs.</p><p>Over the course of the evaluation, no changes regarding the use of the electronic medical record (EMR) for evaluation purposes were reported. Both before and after the evaluation the EMR was primarily used for patient booking, charting and communication purposes. &#x0201c;It is just for recording and booking&#x0201d; (preP1:1:2). &#x0201c;To get a medical history and see what other people have done with the client&#x02026;and then we use more the messaging for the referrals&#x0201d; (preP2:14:40). However there was an acknowledgement that the EMR could facilitate ongoing evaluation. &#x0201c;I think that it is the next step. I think we have the paper end of things&#x02026;now we need to put that over to the EMR&#x0201d; (postP3:17:80). From an administration perspective, the EMR was also used for statistical purposes to identify numbers of patients and to obtain targeted outcomes for mandated reporting; not as a means to inform practice.</p><p>The open-ended responses on the CPAT [<xref ref-type="bibr" rid="CR31">31</xref>] suggested an overall lack of communication between the Memory Clinic and broader primary care organization, which included 7 physicians, a dietician, a nurse practitioner, and a respiratory therapist. Post-evaluation CPAT results identified the need for collaboration with the broader clinic as the most important area of improvement within their own team. Additionally, communication to the broader primary care clinic was identified as a challenge to the team&#x02019;s own collaboration. Given the lack of communication at a clinical level, it is not surprising that the evaluation did not exert an influence on the primary care organization.</p></sec><sec id="Sec27"><title>Diffusion across organizations</title><p>Despite the lack of influence on the immediate organization, its unintended influence was demonstrated in two external organizations. In the first case, one of the members of the Memory Clinic team, who represented a community agency, described how the evaluation changed how she would collect data to inform her practice. As a result, new data collection mechanisms were created that subsequently altered the practices of another individual within the second organization. &#x0201c;I learned more about how I might be able to collect that type of information&#x02026;I was able to give that information to my co-worker&#x02026;and then he went and changed [how he collected information]&#x0201d; (fpP1:21:114).</p><p>In the second case, the Executive Director of the primary care organization became a manager at a new health organization and brought evaluative thinking with her. The implications of this experience laid the foundation for thinking about how evaluation might be embedded into the new organization. &#x0201c;Evaluation; we have to&#x02026;build a framework or some sort of guidelines for every program that we do&#x02026; there is an evaluation component&#x0201d; (fpP2:1:2).</p><p>So while the capacity of the original primary health organization did not appear to be enhanced within the time frame of this study, individuals who were involved began to see themselves as having a responsibility for carrying over what they had learned through evaluative inquiry into their new settings.</p></sec></sec></sec><sec id="Sec28"><title>Discussion</title><p>Ultimately this study sought to encourage more expansive thinking about how evaluation can be used in primary care to bridge the evidence to practice gaps. The study provides evidence that evaluation processes and results can influence health care practices in primary care.</p><sec id="Sec29"><title>Supporting practice-based knowledge</title><p>At the level of the individual, participating in a participatory evaluation designed to support KT influenced individuals&#x02019; knowledge about the program, attitudes towards practice-based knowledge and clinical practices and processes. Both the emerging evaluation results and activities, including weekly e-newsletters, were important sources of knowledge. The study clearly supports the literature that has found primary care clinicians rely heavily on practice-based tacit knowledge and colleagues [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR36">36</xref>]. An ethnographic study exploring decision making of primary care clinicians, found clinicians rarely accessed, appraised, and used explicit evidence directly from research or other formal sources [<xref ref-type="bibr" rid="CR37">37</xref>]. Instead, the authors describe the use of &#x02018;mindlines&#x02019;; internalized tacit guidelines, in part informed by brief reading, but primarily informed by their interactions with each other, with opinion leaders, and by other sources of largely tacit knowledge. Mindlines are built on early training, their own and their colleagues&#x02019; experience and reinforced by the collective practice. The evaluation process was particularly congruent with the notion of building mindlines through its emphasis on practice-based knowledge, integration of context sensitive research, and a participatory approach that offered opportunities to interact and engage in the process of inquiry.</p><p>Clinicians&#x02019; self-reported orientation and participation in research did not change over the 8-month evaluation. A few factors may have contributed to this. Questions on the EROS [<xref ref-type="bibr" rid="CR26">26</xref>] relate specifically to research and do not use broader terms of inquiry or evaluation to which the clinicians may have more readily related. As well, the Memory Clinic makes up only a small portion of clinicians&#x02019; roles within the primary care organization and therefore the evaluation of the Memory Clinic may not have been influential enough to tip the clinicians&#x02019; orientation or attitude towards research. The results provided further evidence however that primary care clinicians are still not oriented toward research. Evaluation has been described as ideally situated to bridge the research-practice divide [<xref ref-type="bibr" rid="CR38">38</xref>]. The evaluation facilitated a positive attitude towards practice-based inquiry and the learning that occurs in this process. There is a growing body of literature on the role of evaluation in supporting both individual and organizational learning [<xref ref-type="bibr" rid="CR39">39</xref>&#x02013;<xref ref-type="bibr" rid="CR41">41</xref>]. This study lends further support to this work and highlights evaluations important role in knowledge exchange in primary care.</p><p>Patient and caregiver feedback data appeared to have the greatest influence on practice behaviors and was the impetus for many of the ongoing program refinements. This is an interesting finding and offers a more fine-grained understanding as to the sources of data that may be most influential to clinical behaviors. Christie [<xref ref-type="bibr" rid="CR42">42</xref>] used the Pathways of Influence [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>] to examine influence of evaluation data on decision makers actions. Christie [<xref ref-type="bibr" rid="CR42">42</xref>] found that large scale and case study data were most influential, suggesting that different contexts and stakeholders attend to data in different ways. In a primary care setting, evaluation processes and results may be most influential when there is a clear link to patient services and outcomes. This study did not include patients or families on the evaluation committee however these results suggest that including this stakeholder perspective could further sensitize the team to patient data.</p><p>A fundamental goal of KT is to &#x0201c;improve the health of Canadians&#x0201d; [<xref ref-type="bibr" rid="CR3">3</xref>]. This study explored the behaviors of the clinicians, but did not examine how the evaluation influenced patient and family outcomes. Because the evaluation began prior to the start of the program there was no baseline data upon which to measure changes in patient outcomes. Further research that includes patient outcomes is required to more fully explore the role evaluation to support KT.</p></sec><sec id="Sec30"><title>Interpersonal</title><p>The evaluation was seen to influence interpersonal behaviors through the development of social norms. Research on interprofessional collaboration in primary care has identified the development of common patient goals as an important indicator of team function [<xref ref-type="bibr" rid="CR43">43</xref>, <xref ref-type="bibr" rid="CR44">44</xref>]. The results of the study suggest that an evaluation can also provide a common goal and focus for a primary care team. The evaluation was seen to influence the team&#x02019;s social norms, supporting the team in thinking beyond their disciplinary boundaries and develop a shared vision and common language. No other studies could be found that examined the influence of evaluation on interprofessional primary care practice. With increasing focus on interprofessional models of primary care and emphasis on quality improvement initiatives it is important to understand how evaluation can support collaboration and is an area that warrants further exploration. Despite the small participant numbers, a significant difference was found on five of the eight CPAT [<xref ref-type="bibr" rid="CR31">31</xref>] subscales, suggesting that the CPAT [<xref ref-type="bibr" rid="CR31">31</xref>] could be a potentially powerful tool to examine interprofessional collaboration.</p><p>While the evaluation helped establish common program goals and objectives, 3&#x000a0;months after the evaluation ended the team was almost entirely new. Turnover of program personnel is common within health care and an important element to consider in any KT study. A study conducted in a hospital environment reported 1-year turnover rates of 49&#x000a0;% for allied health, 29&#x000a0;% for nurses and 9&#x000a0;% for physicians [<xref ref-type="bibr" rid="CR45">45</xref>]. Woltmann and colleagues [<xref ref-type="bibr" rid="CR46">46</xref>] examined the impact of turnover on evidence-based practices. Seventy one per cent of respondents reported that turnover influenced the implementation of the evidence-based guidelines [<xref ref-type="bibr" rid="CR46">46</xref>].</p><p>Within the current study the team had developed clear strategies to translate clinical knowledge to new members. There was less evidence of strategies to support the ongoing use of program-based evidence, or the translation of evaluation knowledge to new members. This finding has a number of potential implications for future evaluations. Looking back to the three dimensions of participatory evaluation [<xref ref-type="bibr" rid="CR24">24</xref>], the evaluator led the overall evaluation with input from the team. While this ensured the ongoing implementation of processes to support learning and knowledge exchange during the evaluation, it did not adequately consider the maintenance of these after its completion. In other words the long-term influence of the evaluation to support ongoing knowledge translation appeared limited. The results suggest that divesting control, or a graded approach, where the evaluator fades out over time, might enable the evaluation to have greater long-term influence. However, further research needs to be completed to determine the longer-term impact of participating in evaluation and what elements and activities could help support long-term influence.</p><p>The fact that one individual led the strategies to translate clinical knowledge, suggests that the influence of one person should not be underestimated. Garcia-Irarte, and colleagues [<xref ref-type="bibr" rid="CR47">47</xref>] have described how one individual served as an effective catalyst for building evaluation capacity within a community based organization. Similarly, a systematic review found opinion leaders, both alone or combined with other strategies, were effective in promoting evidence-based practice [<xref ref-type="bibr" rid="CR48">48</xref>]. These studies, as well as results from the current study suggest that a KT-informed evaluation also needs a dedicated leader. Primary care organizations should consider formally identifying an individual or role within the team to translate evaluation knowledge and facilitate processes that support evaluation as an ongoing form of KT within primary care.</p></sec><sec id="Sec31"><title>Collective</title><p>The study found the evaluation did not have any immediate influence on the primary care organization in which the Memory Clinic was situated. To some extent this is contrary to what would be expected based on the growing body of literature on evaluation capacity building. Evaluation capacity building (ECB) is described as the &#x0201c;intentional work to continuously create and sustain overall organizational processes that make quality evaluation and its uses routine in organizations&#x0201d; [<xref ref-type="bibr" rid="CR49">49</xref>]. A recent systematic review of the ECB literature found that 92&#x000a0;% of evaluations reviewed produced changes at the level of the individual and 77&#x000a0;% demonstrated organizational level changes [<xref ref-type="bibr" rid="CR50">50</xref>].</p><p>The Pathways of Influence model [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] can help to explain these findings. The intentional evaluation activities were focused on supporting KT at the level of the individuals and interpersonal, suggesting that evaluation processes and activities are most likely to influence the level at which they are targeted. In other words, building individual knowledge does not appear to directly influence the collective. The KT literature has largely described interventions that have targeted individuals and there is increasing attention being paid to organizational level interventions [<xref ref-type="bibr" rid="CR51">51</xref>]. As evaluations have been shown to support organizational learning, future evaluations are encouraged to include activities that specifically target the organization.</p></sec><sec id="Sec32"><title>Policy implications &#x02013; continuous quality improvement</title><p>Continuous quality improvement (CQI) is one of the key elements of primary care reforms in both Canada and abroad [<xref ref-type="bibr" rid="CR52">52</xref>]. The findings of this research can provide important insights into CQI initiatives in primary care. In the province of Ontario, Canada, where this research was conducted, a number of recent policy initiatives and documents [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>] create a context that is ideally situated to receive and potentially implement recommendations from this research. Not only have recent provincial health policy documents viewed primary care as the &#x0201c;natural anchor for patients in our health care system&#x0201d; ([<xref ref-type="bibr" rid="CR53">53</xref>] p. 8), but there is a provincial goal to &#x0201c;expand our focus on quality improvement to family health care, and ensure that all family health care providers are equipped to integrate the latest evidence-based care into their practice&#x0201d; ([<xref ref-type="bibr" rid="CR53">53</xref>], p. 9). A specific organization dedicated to supporting quality improvement activities, Health Quality Ontario, has been established by the provincial government [<xref ref-type="bibr" rid="CR55">55</xref>] and yearly documentation is submitted by all interprofessional primary are teams to support quality improvement. While there is infrastructure to support CQI documentation, there are no processes to: 1) engage primary care providers in quality improvement initiatives, 2) provide findings to clinicians in a clinically meaningful way, or 3) link this data to evidence-based practice.</p><p>This research suggests that not only can evaluation provide program specific knowledge to support ongoing professional learning and program improvements, but highlights that strategies and activities can be intentionally included to support learning. Specifically CQI could: (a) include activities to promote individual and organizational learning so CQI activities are meaningfully imbedded into practice, (b) ensure the CQI process is collaborative in nature and inclusive of interprofessional perspectives, (c) embed opportunities for discussion and reflection so teams can make meaning of the data, and (d) use the CQI to identify relevant research and knowledge networks to further support learning. This study also suggests there is a need to either intentionally build capacity of individuals, teams and organizations to facilitate CQI within primary care, or to provide financial or human resources to support the ongoing learning and improvement process.</p></sec><sec id="Sec33"><title>Future research</title><p>The case study method provided an in-depth look at one evaluation designed to support KT and while it provides insights into the role and potential of evaluation, the results cannot be generalized broadly. It is anticipated that additional sites could provide further insights into the influence of evaluation in supporting knowledge exchange. Given that the study only included follow-up at 3-months, it would be of interest to examine the long-term influence of a KT-informed evaluation one to two years after the evaluation. Intentional KT activities were focused on the individuals and team. Future work is required that includes activities targeted at building KT capacity of the organization. Finally, additional studies should consider the influence of a KT-informed evaluation on patient outcomes.</p></sec></sec><sec id="Sec34"><title>Conclusion</title><p>This study provides the first known exploration how evaluation can support KT in primary care. Evaluation is a fundamental component in building quality primary care and is ideally situated to support individual, team and organizational learning by offering an accessible, applicable and relevant form of KT.</p><p>This research identified a number of strategies, structures and approaches that supported KT throughout the evaluation.<list list-type="order"><list-item><p>A participatory approach is a basis requirement for any evaluation designed to support KT and congruent with recommendation of adopting an IKT approach in primary care. Engagement of stakeholders should be as deep as is feasible within the program&#x02019;s context in order to support learning and knowledge translation.</p></list-item><list-item><p>The evaluator needs to have sustained and deep interaction with the program. Doing so provides an understanding of (a) the program and its processes, (b) the types of knowledge that is valued and used, (c) the format in which knowledge is best received, (d) team interactions, (e) organizational culture.</p></list-item><list-item><p>The evaluator must capitalize on the knowledge-brokering role of the community stakeholders, providing them with opportunities and structures to both bring knowledge into the program, and share program knowledge with the broader community.</p></list-item><list-item><p>The evaluator needs to commit to gaining a strong understanding of the empirical literature that grounds the program. Not only does this provide credibility, but provides the foundation to ensure that relevant and contextual empirical evidence is woven throughout the evaluation.</p></list-item><list-item><p>The evaluator needs to gain an understanding of the broader knowledge networks that can inform the program. Many knowledge networks function as online communities and therefore the ability to navigate and critique online resources is required.</p></list-item><list-item><p>In order to support ongoing refinements to practice there needs to be frequent and ongoing communication of both emerging evaluation results and relevant empirical evidence and resources. The evaluator must be sensitive to the frequency of communication, so as not to overwhelm the program.</p></list-item><list-item><p>The evaluator needs to build in opportunities for the program to engage in conversation around emerging evaluation results and actively support knowledge exchange. For example, regular meetings that focus on meaningful program data and attend specifically to patient feedback and data will likely enhance the integration of this knowledge into practice.</p></list-item><list-item><p>The evaluator must be intentional in building the capacity of individuals, the team and the organization. Findings from this research show that activities must targeted both the individual and organization to ensure the KT-informed evaluation exerts an influence at each of these levels.</p></list-item></list>
</p></sec></body><back><app-group><app id="App1"><sec id="Sec35"><title>Additional file</title><p>
<media position="anchor" xlink:href="12875_2016_538_MOESM1_ESM.docx" id="MOESM1"><label>Additional file 1:</label><caption><p>Memory Clinic Knowledge Questionnaire. Word Document (DOCX 16 kb)</p></caption></media>
</p></sec></app></app-group><glossary><title>Abbreviations</title><def-list><def-item><term>CPAT</term><def><p>Collaborative practice assessment tool</p></def></def-item><def-item><term>ECB</term><def><p>Evaluation capacity building</p></def></def-item><def-item><term>EROS</term><def><p>Edmonton research orientation survey</p></def></def-item><def-item><term>IKT</term><def><p>Integrated knowledge translation</p></def></def-item><def-item><term>KT</term><def><p>Knowledge translation</p></def></def-item><def-item><term>ORID framework</term><def><p>Objective, reflective, interpretive, and decisional framework</p></def></def-item></def-list></glossary><ack><title>Acknowledgements</title><p>We gratefully acknowledge the members of the Memory Clinic who participated in this study.</p><sec id="FPar1"><title>Funding</title><p>CD was supported by Strategic CIHR Training Fellowship, Transdisciplinary Understanding and Training on Research: Primary Health Care (TUTOR- PHC).</p></sec><sec id="FPar2"><title>Availability of data and materials</title><p>The datasets during and/or analysed during the current study available from the corresponding author on reasonable request.</p></sec><sec id="FPar3"><title>Authors&#x02019; contributions</title><p>CD conceived of the study and carried out the data collection, analysis and drafted the manuscript. LS participated in the conception of the study, study design and participated in qualitative analysis. DK participated in the study design. LL participated in the design of the study. All authors participated in the drafting of the article and have read and approved the final manuscript.</p></sec><sec id="FPar4"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec id="FPar5"><title>Consent for publication</title><p>Not applicable.</p></sec><sec id="FPar6"><title>Ethics approval and consent to participate</title><p>Ethics approval was provided by the Queen&#x02019;s University Health Sciences and Affiliated Teaching Hospitals Research Ethics Board (HSREB) (approval #6006766). Each participant provided written and informed consent to participate in the study and were made aware that results from the study would be disseminated and published.</p></sec></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menear</surname><given-names>M</given-names></name><name><surname>Grindrod</surname><given-names>K</given-names></name><name><surname>Clouston</surname><given-names>K</given-names></name><name><surname>Norton</surname><given-names>P</given-names></name><name><surname>L&#x000e9;gar&#x000e9;</surname><given-names>F</given-names></name></person-group><article-title>Advancing knowledge translation in primary care</article-title><source>Can Fam Physician</source><year>2012</year><volume>58</volume><fpage>623</fpage><lpage>7</lpage><pub-id pub-id-type="pmid">22859625</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaulieu</surname><given-names>M-D</given-names></name><name><surname>Proulx</surname><given-names>M</given-names></name><name><surname>Jobin</surname><given-names>G</given-names></name><name><surname>Kugler</surname><given-names>M</given-names></name><name><surname>Gossard</surname><given-names>F</given-names></name><name><surname>Denis</surname><given-names>J-L</given-names></name><name><surname>Larouche</surname><given-names>D</given-names></name></person-group><article-title>When Is Knowledge Ripe for Primary Care? An Exploratory Study on the Meaning of Evidence</article-title><source>Eval Health Prof</source><year>2008</year><volume>31</volume><fpage>22</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1177/0163278707311870</pub-id><pub-id pub-id-type="pmid">18245720</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Canadian Institute of Health Research: Guide to knowledge translation planning at CIHR: Integrated and End-of-Grant Approaches. 2015. <ext-link ext-link-type="uri" xlink:href="http://cihr-irsc.gc.ca/e/45321.html">http://cihr-irsc.gc.ca/e/45321.html</ext-link>. Accessed 23 July 2015.</mixed-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>ID</given-names></name><name><surname>Logan</surname><given-names>J</given-names></name><name><surname>Harrison</surname><given-names>MB</given-names></name><name><surname>Straus</surname><given-names>SE</given-names></name><name><surname>Tetroe</surname><given-names>J</given-names></name><name><surname>Caswell</surname><given-names>W</given-names></name><name><surname>Robinson</surname><given-names>N</given-names></name></person-group><article-title>Lost in knowledge translation: time for a map?</article-title><source>J Contin Educ Health Prof</source><year>2006</year><volume>26</volume><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1002/chp.47</pub-id><pub-id pub-id-type="pmid">16557505</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davison</surname><given-names>CM</given-names></name></person-group><article-title>Knowledge translation: Implications for evaluation</article-title><source>N Dir Eval</source><year>2009</year><volume>2009</volume><fpage>75</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1002/ev.315</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhattacharyya</surname><given-names>OK</given-names></name><name><surname>Estey</surname><given-names>EA</given-names></name><name><surname>Zwarenstein</surname><given-names>M</given-names></name></person-group><article-title>Methodologies to evaluate the effectiveness of knowledge translation interventions: a primer for researchers and health care managers</article-title><source>J Clin Epidemiol</source><year>2011</year><volume>64</volume><fpage>32</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2010.02.022</pub-id><pub-id pub-id-type="pmid">21130349</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaBelle Oliver</surname><given-names>M</given-names></name></person-group><article-title>The transfer process: Implications for evaluation</article-title><source>N Dir Eval</source><year>2009</year><volume>2009</volume><fpage>61</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1002/ev.314</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Weiss, C. H. (1981). Measuring the use of evaluation (p. 17&#x02013;33). In J.A. Ciarlo (ed.), Utilizing Evaluation: Concepts and Measurement Techniques. Beverly Hills, CA: Sage 13. Alkin M, Taut S: Unbundling Evaluation Use. Stud Educ Eval 2003, 29:1&#x02013;12.</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Brennan S, McKenzie JE, Whitty P, Buchan H, Green S. Continuous quality improvement: effects on professional practice and healthcare outcomes. The Cochrane Library. 2009;(4):CD003319. doi: 10.1002/14651858.CD003319.pub2.</mixed-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yarbrough</surname><given-names>DB</given-names></name><name><surname>Shulha</surname><given-names>LM</given-names></name><name><surname>Hopson</surname><given-names>RK</given-names></name><name><surname>Caruthers</surname><given-names>FA</given-names></name></person-group><source>The program evaluation standards</source><year>2011</year><edition>3</edition><publisher-loc>Thousand Oaks</publisher-loc><publisher-name>Sage Publications Inc</publisher-name></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cousins</surname><given-names>JB</given-names></name><name><surname>Whitmore</surname><given-names>E</given-names></name></person-group><article-title>Framing participatory evaluation</article-title><source>N Dir Eval</source><year>1998</year><volume>1998</volume><fpage>5</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1002/ev.1114</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Patton</surname><given-names>MQ</given-names></name></person-group><source>Utilization-Focused Evaluation</source><year>2008</year><edition>4</edition><publisher-loc>Los Angeles</publisher-loc><publisher-name>Sage Publications Inc</publisher-name></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su&#x000e1;rez-Herrera</surname><given-names>JC</given-names></name><name><surname>Springett</surname><given-names>J</given-names></name><name><surname>Kagan</surname><given-names>C</given-names></name></person-group><article-title>Critical Connections between Participatory Evaluation, Organizational Learning and Intentional Change in Pluralistic Organizations</article-title><source>Evaluation</source><year>2009</year><volume>15</volume><fpage>321</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1177/1356389009105884</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preskill</surname><given-names>H</given-names></name><name><surname>Torres</surname><given-names>RT</given-names></name></person-group><article-title>The learning dimension of evaluation use</article-title><source>N Dir Eval</source><year>2000</year><volume>2000</volume><fpage>25</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1002/ev.1189</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shulha</surname><given-names>LM</given-names></name><name><surname>Cousins</surname><given-names>JB</given-names></name></person-group><article-title>Evaluation Use: Theory, Research, and Practice Since 1986</article-title><source>Am J Eval</source><year>1997</year><volume>18</volume><fpage>195</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1177/109821409701800121</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collier</surname><given-names>R</given-names></name></person-group><article-title>Verdict still out on family health teams</article-title><source>Can Med Assoc J</source><year>2011</year><volume>183</volume><fpage>1131</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1503/cmaj.109-3864</pub-id><pub-id pub-id-type="pmid">21609998</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jaakkimainen</surname><given-names>L</given-names></name><name><surname>Upshur</surname><given-names>R</given-names></name><name><surname>Klein-Geltink</surname><given-names>JE</given-names></name><name><surname>Leong</surname><given-names>A</given-names></name><name><surname>Maaten</surname><given-names>S</given-names></name><name><surname>Schultz</surname><given-names>SE</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><source>Primary care in Ontario: ICES Atlas</source><year>2006</year></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname><given-names>GT</given-names></name><name><surname>Mark</surname><given-names>MM</given-names></name></person-group><article-title>Beyond Use: Understanding Evaluation&#x02019;s Influence on Attitudes and Actions</article-title><source>Am J Eval</source><year>2003</year><volume>24</volume><fpage>293</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1177/109821400302400302</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mark</surname><given-names>MM</given-names></name><name><surname>Henry</surname><given-names>GT</given-names></name></person-group><article-title>The Mechanisms and Outcomes of Evaluation Influence</article-title><source>Evaluation</source><year>2004</year><volume>10</volume><fpage>35</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1177/1356389004042326</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>R</given-names></name><name><surname>Stevenson</surname><given-names>F</given-names></name><name><surname>Ong</surname><given-names>BN</given-names></name><name><surname>Dziedzic</surname><given-names>K</given-names></name><name><surname>Treweek</surname><given-names>S</given-names></name><name><surname>Eldridge</surname><given-names>S</given-names></name><name><surname>Everitt</surname><given-names>H</given-names></name><name><surname>Kennedy</surname><given-names>A</given-names></name><name><surname>Qureshi</surname><given-names>N</given-names></name><name><surname>Rogers</surname><given-names>A</given-names></name><name><surname>Peacock</surname><given-names>R</given-names></name></person-group><article-title>Achieving change in primary care&#x02014;causes of the evidence to practice gap: systematic reviews of reviews</article-title><source>Implement Sci</source><year>2016</year><volume>11</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="pmid">26727969</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>RK</given-names></name></person-group><source>Case study research: Design and methods</source><year>2009</year><edition>3</edition><publisher-loc>Thousand Oaks</publisher-loc><publisher-name>Sage Publications Inc</publisher-name></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stake</surname><given-names>R</given-names></name></person-group><source>The art of case study research</source><year>1995</year><publisher-loc>Thousand Oaks</publisher-loc><publisher-name>Sage Publications Inc</publisher-name></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>L</given-names></name><name><surname>Hillier</surname><given-names>LM</given-names></name><name><surname>Stolee</surname><given-names>P</given-names></name><name><surname>Heckman</surname><given-names>G</given-names></name><name><surname>Gagnon</surname><given-names>M</given-names></name><name><surname>McAiney</surname><given-names>CA</given-names></name><name><surname>Harvey</surname><given-names>D</given-names></name></person-group><article-title>Enhancing dementia care: a primary care-based memory clinic</article-title><source>J Am Geriatr Soc</source><year>2010</year><volume>58</volume><fpage>2197</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1111/j.1532-5415.2010.03130.x</pub-id><pub-id pub-id-type="pmid">20977435</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cousins</surname><given-names>JB</given-names></name><name><surname>Whitmore</surname><given-names>E</given-names></name><name><surname>Shulha</surname><given-names>L</given-names></name></person-group><article-title>Arguments for a Common Set of Principles for Collaborative Inquiry in Evaluation</article-title><source>Am J Eval</source><year>2013</year><volume>34</volume><fpage>7</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1177/1098214012464037</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donnelly</surname><given-names>C</given-names></name><name><surname>Letts</surname><given-names>L</given-names></name><name><surname>Klinger</surname><given-names>D</given-names></name><name><surname>Shulha</surname><given-names>L</given-names></name></person-group><article-title>Supporting knowledge translation through evaluation: Evaluator as knowledge broker</article-title><source>Can J Prog Eval</source><year>2014</year><volume>29</volume><fpage>36</fpage><lpage>61</lpage></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pain</surname><given-names>K</given-names></name><name><surname>Hagler</surname><given-names>P</given-names></name><name><surname>Warren</surname><given-names>S</given-names></name></person-group><article-title>Development of an instrument to evaluate the research orientation of clinical professionals</article-title><source>Can J Rehabil</source><year>1996</year><volume>9</volume><fpage>93</fpage><lpage>100</lpage></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pain</surname><given-names>K</given-names></name><name><surname>Magill-Evans</surname><given-names>J</given-names></name><name><surname>Darrah</surname><given-names>J</given-names></name><name><surname>Hagler</surname><given-names>P</given-names></name><name><surname>Warren</surname><given-names>S</given-names></name></person-group><article-title>Effects of profession and facility type on research utilization by rehabilitation professionals</article-title><source>J Allied Health</source><year>2004</year><volume>33</volume><fpage>3</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">15053214</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonner</surname><given-names>A</given-names></name><name><surname>Sando</surname><given-names>J</given-names></name></person-group><article-title>Examining the knowledge, attitude and use of research by nurses</article-title><source>J Nurs Manag</source><year>2008</year><volume>16</volume><fpage>334</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2834.2007.00808.x</pub-id><pub-id pub-id-type="pmid">18324993</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>A</given-names></name><name><surname>Winch</surname><given-names>S</given-names></name><name><surname>Holzhauser</surname><given-names>K</given-names></name><name><surname>De Vries</surname><given-names>S</given-names></name></person-group><article-title>The motivation of health professionals to explore research evidence in their practice: An intervention study</article-title><source>J Clin Nurs</source><year>2006</year><volume>15</volume><fpage>1559</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2702.2006.01637.x</pub-id><pub-id pub-id-type="pmid">17118078</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Squires</surname><given-names>JE</given-names></name><name><surname>Estabrooks</surname><given-names>CA</given-names></name><name><surname>O&#x02019;Rourke</surname><given-names>HM</given-names></name><name><surname>Gustavsson</surname><given-names>P</given-names></name><name><surname>Newburn-Cook</surname><given-names>CV</given-names></name><name><surname>Wallin</surname><given-names>L</given-names></name></person-group><article-title>A systematic review of the psychometric properties of self-report research utilization measures used in healthcare</article-title><source>Implement Sci</source><year>2011</year><volume>6</volume><fpage>83</fpage><pub-id pub-id-type="doi">10.1186/1748-5908-6-83</pub-id><pub-id pub-id-type="pmid">21794144</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroder</surname><given-names>C</given-names></name><name><surname>Medves</surname><given-names>J</given-names></name><name><surname>Paterson</surname><given-names>M</given-names></name><name><surname>Byrnes</surname><given-names>V</given-names></name><name><surname>Chapman</surname><given-names>C</given-names></name><name><surname>O&#x02019;Riordan</surname><given-names>A</given-names></name><name><surname>Pichora</surname><given-names>D</given-names></name><name><surname>Kelly</surname><given-names>C</given-names></name></person-group><article-title>Development and pilot testing of the collaborative practice assessment tool</article-title><source>J Interprof Care</source><year>2011</year><volume>25</volume><fpage>189</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.3109/13561820.2010.532620</pub-id><pub-id pub-id-type="pmid">21182434</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stanfield</surname><given-names>BR</given-names></name></person-group><source>The art of focused conversation</source><year>2000</year><publisher-loc>Gabriola Island</publisher-loc><publisher-name>New Society Publishers</publisher-name></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Villeneuve</surname><given-names>M</given-names></name><name><surname>Jamieson</surname><given-names>M</given-names></name><name><surname>Donnelly</surname><given-names>C</given-names></name><name><surname>White</surname><given-names>C</given-names></name><name><surname>Lava</surname><given-names>J</given-names></name></person-group><article-title>Theory to practice learning: Two approaches</article-title><source>Acad Exch Q</source><year>2009</year><volume>13</volume><fpage>19</fpage></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krefting</surname><given-names>L</given-names></name></person-group><article-title>Rigor in Qualitative Research: The Assessment of Trustworthiness</article-title><source>Am J Occup Ther</source><year>1991</year><volume>45</volume><fpage>214</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.5014/ajot.45.3.214</pub-id><pub-id pub-id-type="pmid">2031523</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golafshani</surname><given-names>N</given-names></name></person-group><article-title>Understanding reliability and validity in qualitative research</article-title><source>Qual Rep</source><year>2003</year><volume>8</volume><fpage>597</fpage><lpage>607</lpage></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pappano</surname><given-names>D</given-names></name><name><surname>Conners</surname><given-names>G</given-names></name><name><surname>McIntosh</surname><given-names>S</given-names></name><name><surname>Humiston</surname><given-names>S</given-names></name><name><surname>Roma</surname><given-names>D</given-names></name></person-group><article-title>Sources of knowledge transfer among primary care pediatric health care providers</article-title><source>Clin Pediatr (Phila)</source><year>2008</year><volume>47</volume><fpage>930</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1177/0009922808320600</pub-id><pub-id pub-id-type="pmid">18626107</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Gabbay J, le May A. Evidence based guidelines or collectively constructed &#x0201c;mindlines?&#x0201d; Ethnographic study of knowledge management in primary care. BMJ. 2004;329:1013.</mixed-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urban</surname><given-names>JB</given-names></name><name><surname>Trochim</surname><given-names>W</given-names></name></person-group><article-title>The Role of Evaluation in Research&#x02014;Practice Integration Working Toward the &#x0201c;&#x02018;Golden Spike&#x02019;&#x0201d;</article-title><source>Am J Eval</source><year>2009</year><volume>30</volume><fpage>538</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1177/1098214009348327</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Preskill</surname><given-names>H</given-names></name><name><surname>Torres</surname><given-names>RT</given-names></name></person-group><source>Evaluative inquiry for learning in organizations</source><year>1999</year><publisher-loc>Thousand Oaks</publisher-loc><publisher-name>Sage Publications Inc</publisher-name></element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preskill</surname><given-names>H</given-names></name><name><surname>Torres</surname><given-names>RT</given-names></name></person-group><article-title>Building Capacity for Organizational Learning Through Evaluative Inquiry</article-title><source>Evaluation</source><year>1999</year><volume>5</volume><fpage>42</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1177/13563899922208814</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torres</surname><given-names>RT</given-names></name><name><surname>Preskill</surname><given-names>H</given-names></name></person-group><article-title>Evaluation and organizational learning: past, present, and future</article-title><source>Am J Eval</source><year>2001</year><volume>22</volume><fpage>387</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1177/109821400102200316</pub-id></element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christie</surname><given-names>CA</given-names></name></person-group><article-title>Reported Influence of Evaluation Data on Decision Makers&#x02019; Actions An Empirical Examination</article-title><source>Am J Eval</source><year>2007</year><volume>28</volume><fpage>8</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1177/1098214006298065</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulton</surname><given-names>BC</given-names></name><name><surname>West</surname><given-names>MA</given-names></name></person-group><article-title>The determinants of effectiveness in primary health care teams</article-title><source>J Interprof Care</source><year>1999</year><volume>13</volume><fpage>7</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.3109/13561829909025531</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaw</surname><given-names>A</given-names></name><name><surname>de Lusignan</surname><given-names>S</given-names></name><name><surname>Rowlands</surname><given-names>G</given-names></name></person-group><article-title>Do primary care professionals work as a team: a qualitative study</article-title><source>J Interprof Care</source><year>2005</year><volume>19</volume><fpage>396</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1080/13561820500053454</pub-id><pub-id pub-id-type="pmid">16076600</pub-id></element-citation></ref><ref id="CR45"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waldman</surname><given-names>JD</given-names></name><name><surname>Kelly</surname><given-names>F</given-names></name><name><surname>Arora</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>HL</given-names></name></person-group><article-title>The shocking cost of turnover in health care</article-title><source>Health Care Manage Rev</source><year>2004</year><volume>29</volume><fpage>2</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1097/00004010-200401000-00002</pub-id><pub-id pub-id-type="pmid">14992479</pub-id></element-citation></ref><ref id="CR46"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woltmann</surname><given-names>EM</given-names></name><name><surname>Whitley</surname><given-names>R</given-names></name><name><surname>McHugo</surname><given-names>GJ</given-names></name><name><surname>Brunette</surname><given-names>M</given-names></name><name><surname>Torrey</surname><given-names>WC</given-names></name><name><surname>Coots</surname><given-names>L</given-names></name><name><surname>Lynde</surname><given-names>D</given-names></name><name><surname>Drake</surname><given-names>RE</given-names></name></person-group><article-title>The role of staff turnover in the implementation of evidence-based practices in mental health care</article-title><source>Psychiatr Serv</source><year>2008</year><volume>59</volume><fpage>732</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1176/ps.2008.59.7.732</pub-id><pub-id pub-id-type="pmid">18586989</pub-id></element-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garc&#x000ed;a-Iriarte</surname><given-names>E</given-names></name><name><surname>Suarez-Balcazar</surname><given-names>Y</given-names></name><name><surname>Taylor-Ritzler</surname><given-names>T</given-names></name><name><surname>Luna</surname><given-names>M</given-names></name></person-group><article-title>A Catalyst-for-Change Approach to Evaluation Capacity Building</article-title><source>Am J Eval</source><year>2011</year><volume>32</volume><fpage>168</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1177/1098214010387114</pub-id></element-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">Flodgren G, Parmelli E, Doumit G, Gattellari M, O&#x02019;Brien MA, Grimshaw J, Eccles MP: Local opinion leaders: effects on professional practice and health care outcomes. Cochrane Database Syst. Rev<italic>.</italic> 2011:CD000125. doi:10.1002/14651858.CD000125.pub4</mixed-citation></ref><ref id="CR49"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hueftle Stockdill</surname><given-names>S</given-names></name><name><surname>Baizerman</surname><given-names>M</given-names></name><name><surname>Compton</surname><given-names>DW</given-names></name></person-group><article-title>Toward a definition of the ECB process: A conversation with the ECB literature</article-title><source>N Dir Eval</source><year>2002</year><volume>2002</volume><fpage>7</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1002/ev.39</pub-id></element-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Labin SN, Duffy JL, Meyers DC, Wandersman A, Lesesne CA: A Research Synthesis of the Evaluation Capacity Building Literature. Am J Eval. 2012;1098214011434608.</mixed-citation></ref><ref id="CR51"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenhalgh</surname><given-names>T</given-names></name><name><surname>Robert</surname><given-names>G</given-names></name><name><surname>Macfarlane</surname><given-names>F</given-names></name><name><surname>Bate</surname><given-names>P</given-names></name><name><surname>Kyriakidou</surname><given-names>O</given-names></name></person-group><article-title>Diffusion of innovations in service organizations: systematic review and recommendations</article-title><source>Milbank Q</source><year>2004</year><volume>82</volume><fpage>581</fpage><lpage>629</lpage><pub-id pub-id-type="doi">10.1111/j.0887-378X.2004.00325.x</pub-id><pub-id pub-id-type="pmid">15595944</pub-id></element-citation></ref><ref id="CR52"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchison</surname><given-names>B</given-names></name><name><surname>Levesque</surname><given-names>JF</given-names></name><name><surname>Strumpf</surname><given-names>E</given-names></name><name><surname>Coyle</surname><given-names>N</given-names></name></person-group><article-title>Primary health care in Canada: systems in motion</article-title><source>Milbank Q</source><year>2011</year><volume>89</volume><fpage>256</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1111/j.1468-0009.2011.00628.x</pub-id><pub-id pub-id-type="pmid">21676023</pub-id></element-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="other">Ontario&#x02019;s Action Plan for Health C 2012. <ext-link ext-link-type="uri" xlink:href="http://www.health.gov.on.ca/en/ms/ecfa/healthy_change/docs/rep_healthychange.pdf">http://www.health.gov.on.ca/en/ms/ecfa/healthy_change/docs/rep_healthychange.pdf</ext-link>. Accessed 3 June 2016.</mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="other">Patients First: Action Plan for Health Care 2015. <ext-link ext-link-type="uri" xlink:href="http://www.health.gov.on.ca/en/ms/ecfa/healthy_change/docs/rep_patientsfirst.pdf">http://www.health.gov.on.ca/en/ms/ecfa/healthy_change/docs/rep_patientsfirst.pdf</ext-link>. Accessed 3 June 2016.</mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Health Quality Ontario. Primary Care Sector Performance. <ext-link ext-link-type="uri" xlink:href="http://www.hqontario.ca/System-Performance/Primary-Care-Sector-Performance">http://www.hqontario.ca/System-Performance/Primary-Care-Sector-Performance</ext-link>. Accessed 3 June 2016.</mixed-citation></ref></ref-list></back></article>