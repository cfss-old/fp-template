<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25504147</article-id><article-id pub-id-type="pmc">4263717</article-id><article-id pub-id-type="publisher-id">PONE-D-14-35440</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0114872</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (Mathematics)</subject><subj-group><subject>Biostatistics</subject><subject>Statistical Methods</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Research and Analysis Methods</subject><subj-group><subject>Mathematical and Statistical Techniques</subject></subj-group><subj-group><subject>Research Design</subject><subj-group><subject>Experimental Design</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>A Common Control Group - Optimising the Experiment Design to Maximise Sensitivity</article-title><alt-title alt-title-type="running-head">Using a Common Control</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bate</surname><given-names>Simon</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author"><name><surname>Karp</surname><given-names>Natasha A.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>Statistical Science Europe, GlaxoSmithKline Pharmaceuticals, Stevenage, United Kingdom</addr-line></aff><aff id="aff2"><label>2</label><addr-line>Mouse Informatics Group, Wellcome Trust Sanger Institute, Cambridge, United Kingdom</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Peddada</surname><given-names>Shyamal D.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>National Institute of Environmental and Health Sciences, United States of America</addr-line></aff><author-notes><corresp id="cor1">* E-mail: <email>simon.t.bate@gsk.com</email></corresp><fn fn-type="conflict"><p><bold>Competing Interests: </bold>The authors have read the journal policy and have the following conflicts: Simon Bate is an employee of GlaxoSmithKline at the time this work was carried out. Natasha Karp is an employee of the Sanger Institute at the time this work was carried out. There are no products in development or marketed products to declare. This does not alter the authors' adherence to all the PLOS ONE policies on sharing data and materials, as detailed online in the guide for authors.</p></fn><fn fn-type="con"><p>Conceived and designed the experiments: STB NK. Performed the experiments: STB NK. Analyzed the data: STB NK. Wrote the paper: STB NK.</p></fn></author-notes><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>11</day><month>12</month><year>2014</year></pub-date><volume>9</volume><issue>12</issue><elocation-id>e114872</elocation-id><history><date date-type="received"><day>6</day><month>8</month><year>2014</year></date><date date-type="accepted"><day>14</day><month>11</month><year>2014</year></date></history><permissions><copyright-year>2014</copyright-year><copyright-holder>Bate, Karp</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>Methods for choosing an appropriate sample size in animal experiments have received much attention in the statistical and biological literature. Due to ethical constraints the number of animals used is always reduced where possible. However, as the number of animals decreases so the risk of obtaining inconclusive results increases. By using a more efficient experimental design we can, for a given number of animals, reduce this risk. In this paper two popular cases are considered, where planned comparisons are made to compare treatments back to control and when researchers plan to make all pairwise comparisons. By using theoretical and empirical techniques we show that for studies where all pairwise comparisons are made the traditional balanced design, as suggested in the literature, maximises sensitivity. For studies that involve planned comparisons of the treatment groups back to the control group, which are inherently more sensitive due to the reduced multiple testing burden, the sensitivity is maximised by increasing the number of animals in the control group while decreasing the number in the treated groups.</p></abstract><funding-group><funding-statement>This work was supported by the National Institutes of Health (<ext-link ext-link-type="uri" xlink:href="http://www.nih.gov">www.nih.gov</ext-link>), grant number 1 U54 HG006370-01 (Natasha Karp). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="12"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The authors confirm that all data underlying the findings are fully available without restriction. All relevant data are within the paper.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The authors confirm that all data underlying the findings are fully available without restriction. All relevant data are within the paper.</p></notes></front><body><sec id="s1"><title>Introduction</title><p>The 3R's, Replacement, Reduction and Refinement, introduced as a framework for achieving the most humane treatment of experimental animals, has been widely accepted as a prerequisite for a successful animal experiment <xref rid="pone.0114872-Russell1" ref-type="bibr">[1]</xref>. Attention on the refinement element of the framework has been growing in recent years. Refinement refers to improvements to scientific procedures and husbandry which minimise actual or potential pain, suffering, distress or lasting harm and/or improve animal welfare in situations where the use of animals is unavoidable. In 2009, Kilkenny <italic>et al</italic>. published a systematic review of published papers involving <italic>in vivo</italic> experiments and highlighted that many published experiments did not use the most appropriate experimental design. For example, in the survey only 62% of experiments that should have employed a factorial design had in fact done so <xref rid="pone.0114872-Kilkenny1" ref-type="bibr">[2]</xref>. Experimental design and statistical analysis fall under the refinement element of the 3R's as they reduce further experimentation and ensure that the animals used fulfil the goals of the experiment. This has led to the publication of the Animal Research: Reporting <italic>In Vivo</italic> Experiments (ARRIVE) guidelines <xref rid="pone.0114872-Kilkenny2" ref-type="bibr">[3]</xref>, a checklist that aims to embed good practice in the experimentation process. The impact of poor experimental design can be profound, as shown by a systematic study that found a lack of concordance between animal experiments and clinical trials <xref rid="pone.0114872-Perel1" ref-type="bibr">[4]</xref>. The authors concluded that majority of the animal studies were of poor methodological quality. In practice though poor design and analysis is not restricted to animal experimentation and is thought to be endemic throughout scientific research <xref rid="pone.0114872-Sun1" ref-type="bibr">[5]</xref>, <xref rid="pone.0114872-Ioannidis1" ref-type="bibr">[6]</xref>.</p><p>In science and statistics, validity is the extent to which a conclusion or measurement is reliable and corresponds accurately to the real world. The validity of an experiment can be evaluated in many ways. For example, the conclusion validity is the degree to which conclusions we reach about our data are reasonable <xref rid="pone.0114872-GarcaPrez1" ref-type="bibr">[7]</xref> and relates to the experiment's ability to assess the relationship. The majority of studies involving animals use statistical hypothesis testing, where a <italic>p</italic>-value is calculated to assess whether the null hypothesis (of no effect) can be rejected and hence the alternative hypothesis (the effect you are trying to prove) accepted. With the use of inferential hypothesis testing, there is potential to conclude there is an effect when in fact there is none &#x02013; a false positive (type I error). Conversely, there is potential to conclude there is not an effect when in fact there is one (type II error). When considering the type II error rate it is often more useful to consider the statistical power (<inline-formula><inline-graphic xlink:href="pone.0114872.e001.jpg"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="pone.0114872.e002.jpg"/></inline-formula> is the probability of a type II error occurring). The statistical power is the probability (or chance) of achieving a statistically significant result when conducting a study given that, in reality, there is a real effect <xref rid="pone.0114872-Bate1" ref-type="bibr">[8]</xref>. In practice a power in excess of 80% is usually considered acceptable. With experiments involving animals it is critical to ensure that the experiment has sufficient power so that not only real effects are detected, but also that the experiment is not over-resourced such that animals are wasted <xref rid="pone.0114872-Thomas1" ref-type="bibr">[9]</xref>.</p><p>Frequently, animal researchers conduct experiments that involve multiple treatments and a common control. For example, a survey of recent PLoS ONE papers identified an R&#x00026;D drug study involving multiple different treatments versus a vehicle control <xref rid="pone.0114872-Rozza1" ref-type="bibr">[10]</xref>, a study comparing high cholesterol diets to a low cholesterol diet <xref rid="pone.0114872-Nekohashi1" ref-type="bibr">[11]</xref> and a study comparing responses at later time points to a baseline group <xref rid="pone.0114872-Zhou1" ref-type="bibr">[12]</xref>. This type of study design is also commonly used in toxicology and safety assessment where studies are typically performed so that they can compare increasing doses of a treatment back to a control group. For example, Lee <italic>et al</italic>. <xref rid="pone.0114872-Lee1" ref-type="bibr">[13]</xref> describe a repeated oral dose toxicity study in rats to compare three doses of KMS88009 back to a vehicle control. In these experiments comparisons back to the control will be the only comparisons that are of interest, regardless of the experimental results. It is important to note that the researcher plans which comparisons that wish to make in advance &#x02013; they are examples of so-called planned comparisons <xref rid="pone.0114872-Snedecor1" ref-type="bibr">[14]</xref>, as opposed to general &#x02018;post hoc testing&#x02019; which involves making all pairwise comparisons). Planned comparisons are beneficial for two reasons. Firstly, the decision regarding which tests to perform is made before the data is collected and hence is not influenced by the observed results. In theory, this should reduce the risk of inadvertently finding false positive results in a &#x02018;data-trawling&#x02019; exercise. Secondly, planned comparisons increase the sensitivity of the experiment as it reduces the multiple testing burden. The multiple testing burden arises because the chance of finding a false positive, for a given significance threshold, accumulates with each statistical test conducted. If all pairwise comparisons are performed, for example using an LSD (Least Significant difference) test <xref rid="pone.0114872-Bate1" ref-type="bibr">[8]</xref>, then there is an increased risk of finding false positives. To manage this risk a more stringent threshold is applied; by making a multiple comparison adjustment to the LSD p-values. Consider the scenario with one control group and three treatments. If all groups are compared then the post-hoc testing would involve six separate pairwise statistical comparisons. However, if planned comparisons of treatments back to control are performed then this corresponds to only three separate statistical comparisons and the threshold adjustment would be less. In this paper, we shall consider the implications on the choice of design when the researcher knows in advance which comparisons they wish to make.</p><p>When constructing experimental designs that involve a number of treatment groups and a control group, interest rightly focuses on the sample size that is required in each of the experimental (treatment and control) groups. It appears to be standard practice to assign the same number of animals to each of the experimental groups (the so-called &#x02018;balanced&#x02019; designs). Such practice is perhaps encouraged by sample size calculation software, where typically one sample size is recommended across all groups <xref rid="pone.0114872-Lenth1" ref-type="bibr">[15]</xref>, <xref rid="pone.0114872-Faul1" ref-type="bibr">[16]</xref>. The statistical test applied also influences the sample size required. A common approach used to analyse data generated from these experiments, assuming the parametric assumptions hold, is to compare the treatment group means to the control group mean, using either <italic>t</italic>-tests, Analysis of Variance followed by Dunnett's test or applying a multiple comparison adjustment to the LSD p-values. It is therefore common practice to perform a sample size calculation under the assumption that the statistical analysis will be performed using one of these tests <xref rid="pone.0114872-Clark1" ref-type="bibr">[17]</xref>.</p><p>In this paper, we shall use optimal design theory to investigate the effects of varying the replication of the experimental groups. We shall assume that the data will be analysed using either multiple <italic>t</italic>-tests or Analysis of Variance followed by a suitable multiple comparison procedure. Crucially we differentiate between the experimental situations where the researcher only plans to compare the treatments back to control and when they plan to make all pairwise comparisons. We will focus on the former case, and highlight how different experimental designs result in different levels of statistical power.</p></sec><sec sec-type="methods" id="s2"><title>Methods</title><p>Two approaches are considered in this paper to investigate the effect of varying the control group replication; a theoretical investigation and a power comparison.</p><sec id="s2a"><title>Theoretical approach to maximising sensitivity</title><p>For the theoretical investigation, we need to make a few assumptions. While restrictive, many animal experiments satisfy these assumptions. We assume that:</p><list list-type="order"><list-item><p>The researcher conducts an experiment to either (a) compare <inline-formula><inline-graphic xlink:href="pone.0114872.e003.jpg"/></inline-formula> treatments to a single control or (b) make all possible pairwise comparisons between the experimental groups. The experimental design therefore involves <inline-formula><inline-graphic xlink:href="pone.0114872.e004.jpg"/></inline-formula> experimental groups.</p></list-item><list-item><p>A total of <inline-formula><inline-graphic xlink:href="pone.0114872.e005.jpg"/></inline-formula> animals are used in the experiment and they are allocated at random to the <inline-formula><inline-graphic xlink:href="pone.0114872.e006.jpg"/></inline-formula> experimental groups.</p></list-item><list-item><p>The replication in the <inline-formula><inline-graphic xlink:href="pone.0114872.e007.jpg"/></inline-formula> treatment groups is the same <inline-formula><inline-graphic xlink:href="pone.0114872.e008.jpg"/></inline-formula>.</p></list-item><list-item><p>The replication in the control group is <inline-formula><inline-graphic xlink:href="pone.0114872.e009.jpg"/></inline-formula>.</p></list-item><list-item><p>The variability of the responses is the same across all experimental groups. In practice the response may require a transformation in order to satisfy this condition.</p></list-item><list-item><p>The parametric assumptions hold (for example, the responses are numerical, independent, continuous and the residuals are normally distributed) and hence a parametric test, such as the <italic>t</italic>-test or Analysis of Variance followed by pairwise comparisons, will be used to compare the experimental groups.</p></list-item></list><p>By considering the predicted standard error of the estimates of the comparisons of interest, when using a given experimental design, it is possible to compare and contrast different designs. The more efficient the design, the smaller the predicted standard errors will be and hence the statistical tests will be more sensitive. For a given total number of animals, we use mathematical arguments (see <xref ref-type="supplementary-material" rid="pone.0114872.s001">S1 Derivations</xref> for more details) to investigate how varying the replication of the control group influences these standard errors.</p></sec><sec id="s2b"><title>Power analysis assessment</title><p>To highlight the practical implications of using different experimental designs, we investigate the statistical power that can be achieved when comparing all treatments back to a single common control using planned comparisons. The tests within this manuscript are not adjusted for multiplicity, as the adjustment needed varies between the analysis scenarios and adds complexity to the analysis. The absolute level of statistical power is not of direct interest; rather we are interested in investigating how varying the experimental design (control group replication) influences its statistical power.</p><p>For a given level of variability <inline-formula><inline-graphic xlink:href="pone.0114872.e010.jpg"/></inline-formula>, a difference between the two group means <inline-formula><inline-graphic xlink:href="pone.0114872.e011.jpg"/></inline-formula>, a significance level of 5% and sample sizes <inline-formula><inline-graphic xlink:href="pone.0114872.e012.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0114872.e013.jpg"/></inline-formula>, the power <inline-formula><inline-graphic xlink:href="pone.0114872.e014.jpg"/></inline-formula> of a two-sided test that is not adjusted for multiplicity is given by<disp-formula id="pone.0114872.e015"><graphic xlink:href="pone.0114872.e015.jpg" position="anchor" orientation="portrait"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="pone.0114872.e016.jpg"/></inline-formula> is the cumulative density function (CDF) of the t distribution with <inline-formula><inline-graphic xlink:href="pone.0114872.e017.jpg"/></inline-formula> degrees of freedom and <inline-formula><inline-graphic xlink:href="pone.0114872.e018.jpg"/></inline-formula> is an estimate of the variance <xref rid="pone.0114872-Snedecor1" ref-type="bibr">[14]</xref>. The derivation of this formula is given in <xref ref-type="supplementary-material" rid="pone.0114872.s002">S2 Derivations</xref>.</p><p>Using (1) we investigate the power that can be achieved in various real-life situations. For convenience the total number of animals included in each situation is selected so that <inline-formula><inline-graphic xlink:href="pone.0114872.e019.jpg"/></inline-formula> (where <inline-formula><inline-graphic xlink:href="pone.0114872.e020.jpg"/></inline-formula> is the number of treatment groups and <inline-formula><inline-graphic xlink:href="pone.0114872.e021.jpg"/></inline-formula> is the replication in the treatment groups) is approximately an integer.</p></sec></sec><sec id="s3"><title>Results</title><sec id="s3a"><title>Theoretical approach to maximising sensitivity</title><p>Using the mathematical arguments given in <xref ref-type="supplementary-material" rid="pone.0114872.s001">S1 Derivations</xref> we can, for a variety of scenarios, assess the optimal replication in the control group to achieve for maximum sensitivity. We assume that the researcher is running an experiment that satisfies the five conditions discussed in the methods.</p><sec id="s3a1"><title>Scenario 1</title><p>Assume that the only comparisons the researcher plans to make involve comparing the treatment groups back to the control group. For a given total number of animals <inline-formula><inline-graphic xlink:href="pone.0114872.e022.jpg"/></inline-formula>, if there are <inline-formula><inline-graphic xlink:href="pone.0114872.e023.jpg"/></inline-formula> animals in each of the <inline-formula><inline-graphic xlink:href="pone.0114872.e024.jpg"/></inline-formula> treatment groups and <inline-formula><inline-graphic xlink:href="pone.0114872.e025.jpg"/></inline-formula> animals in the control group, then let there be <inline-formula><inline-graphic xlink:href="pone.0114872.e026.jpg"/></inline-formula> more animals in the control group compared to the treated groups, i.e.<disp-formula id="pone.0114872.e027"><graphic xlink:href="pone.0114872.e027.jpg" position="anchor" orientation="portrait"/></disp-formula>and<disp-formula id="pone.0114872.e028"><graphic xlink:href="pone.0114872.e028.jpg" position="anchor" orientation="portrait"/></disp-formula></p><p>Note if <inline-formula><inline-graphic xlink:href="pone.0114872.e029.jpg"/></inline-formula> then there are more animals in the control group compared to the treated groups and if <inline-formula><inline-graphic xlink:href="pone.0114872.e030.jpg"/></inline-formula> then there are fewer animals in the control group compared to the treated groups.</p><p>The estimates of the pairwise comparisons of interest are as precise as possible if:<disp-formula id="pone.0114872.e031"><graphic xlink:href="pone.0114872.e031.jpg" position="anchor" orientation="portrait"/></disp-formula></p><p>In other words, the number of animals in the control group should be <inline-formula><inline-graphic xlink:href="pone.0114872.e032.jpg"/></inline-formula> times the number in the treatment groups. So in an experiment involving comparing four treatment groups back to a control group, then twice as many animals should be allocated to the control group than are allocated to the treatment groups.</p></sec><sec id="s3a2"><title>Scenario 2</title><p>Assume that the researcher is interested in making all possible pairwise comparisons between the <inline-formula><inline-graphic xlink:href="pone.0114872.e033.jpg"/></inline-formula> experimental groups. It turns out that these comparisons are estimated as precisely as possible if: <disp-formula id="pone.0114872.e034"><graphic xlink:href="pone.0114872.e034.jpg" position="anchor" orientation="portrait"/></disp-formula></p><p>In other words, as expected by symmetry, as all groups are involved in the same number of comparisons, the same number of animals should be allocated to each of the experimental groups (treatment groups and the control group).</p><p>From consideration of these two scenarios, we can see the optimal design depends on the goal of the experiment. With the defined planned comparisons in Scenario 1, an unbalanced design with more animals allocated to the control group results in comparisons that are estimated more precisely. This gain in sensitivity is at the expense of treatment comparisons that the researcher does not plan to make. In other words, the pairwise comparisons of interest are more precise, everything else being equal, if one design is employed when compared to another. From a less mathematical point of view, these results make sense as the control group is used more often than the other treatment means, and hence it is important to have a precise estimate of the control group mean.</p></sec></sec><sec id="s3b"><title>Power analysis assessment for Scenario 1</title><p>We shall now consider Scenario 1 in more detail. The previous analysis identified the optimal design to maximise sensitivity and we now focus on quantifying the impact on the statistical power of the various designs.</p><p>Using <xref ref-type="disp-formula" rid="pone.0114872.e015">equation (1</xref>), the statistical power of various levels of replication of the control group was investigated by assessing various designs when the size of the biological effect increases for a defined amount of biological variability (<xref ref-type="table" rid="pone-0114872-t001">Table 1</xref> and <xref ref-type="fig" rid="pone-0114872-g001">Fig. 1</xref>) and when the size of the biological effect is fixed but the biological variation increases (<xref ref-type="table" rid="pone-0114872-t002">Table 2</xref> and <xref ref-type="fig" rid="pone-0114872-g002">Fig. 2</xref>). Three control group replication strategies are considered: when the replication in the control group is (i) <inline-formula><inline-graphic xlink:href="pone.0114872.e035.jpg"/></inline-formula> more than the treated groups - the theoretically optimal solution, (ii) equal to the replication in the treated groups and (iii) less than the replication in the treated groups. While (i) has been shown to be the optimal solution, (ii) and (iii) are commonly applied in practice and hence it is of interest to consider how these designs compare to the theoretically optimal design. To give context, the biological effect being tested for each calculation has been presented as a standardised effect size (Cohen's <italic>d</italic> or <italic>Z</italic> statistic) where the biological effect is scaled relative to the biological variability (i.e. 1 equals a differences equivalent to one unit of variability) <xref rid="pone.0114872-Cohen1" ref-type="bibr">[18]</xref>.</p><fig id="pone-0114872-g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0114872.g001</object-id><label>Figure 1</label><caption><title>Statistical power of various levels of replication of the control group as the biological effect increases.</title><p>The variability of the responses is fixed at 2.25. Three strategies for selecting the size of the control group were considered: (i) Optimal, according to the theoretical derivation, (ii) Equal to the treatment groups and (iii) Less than, where the control group replication is less than the treatment groups.</p></caption><graphic xlink:href="pone.0114872.g001"/></fig><fig id="pone-0114872-g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0114872.g002</object-id><label>Figure 2</label><caption><title>Statistical power of various levels of replication of the control group as the variability increases.</title><p>The difference between the treatment and control groups is fixed at 2. Three strategies for selecting the size of the control group were considered: (i) Optimal, according to the theoretical derivation, (ii) Equal to the treatment groups and (iii) Less than, where the control group replication is less than the treatment groups.</p></caption><graphic xlink:href="pone.0114872.g002"/></fig><table-wrap id="pone-0114872-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0114872.t001</object-id><label>Table 1</label><caption><title>Statistical power of various levels of replication of the control group as the biological effect increases.</title></caption><alternatives><graphic id="pone-0114872-t001-1" xlink:href="pone.0114872.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Number of treatment groups</td><td align="left" rowspan="1" colspan="1">Control Group Replication Strategy<xref ref-type="table-fn" rid="nt102">&#x02020;</xref></td><td align="left" rowspan="1" colspan="1">Treatment group replication</td><td align="left" rowspan="1" colspan="1">Control group replication</td><td align="left" rowspan="1" colspan="1">Total number of animals</td><td colspan="3" align="left" rowspan="1">Difference between the treatment and control groups (Absolute size, Cohen's <italic>d</italic>)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="pone.0114872.e036.jpg"/></inline-formula></td><td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="pone.0114872.e037.jpg"/></inline-formula></td><td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="pone.0114872.e038.jpg"/></inline-formula></td><td align="left" rowspan="1" colspan="1">(1, 0.67)</td><td align="left" rowspan="1" colspan="1">(2, 1.33)</td><td align="left" rowspan="1" colspan="1">(3, 2)</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">22.47%</td><td align="left" rowspan="1" colspan="1">69.70%</td><td align="left" rowspan="1" colspan="1">95.91%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">21.21%</td><td align="left" rowspan="1" colspan="1">66.63%</td><td align="left" rowspan="1" colspan="1">94.75%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">4<sup>a</sup></td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">17.05%</td><td align="left" rowspan="1" colspan="1">54.64%</td><td align="left" rowspan="1" colspan="1">88.05%</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">20.47%</td><td align="left" rowspan="1" colspan="1">64.60%</td><td align="left" rowspan="1" colspan="1">93.87%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">18.80%</td><td align="left" rowspan="1" colspan="1">59.92%</td><td align="left" rowspan="1" colspan="1">91.46%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">2<sup>b</sup></td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">11.60%</td><td align="left" rowspan="1" colspan="1">34.89%</td><td align="left" rowspan="1" colspan="1">66.78%</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">22</td><td align="left" rowspan="1" colspan="1">72</td><td align="left" rowspan="1" colspan="1">40.24%</td><td align="left" rowspan="1" colspan="1">93.08%</td><td align="left" rowspan="1" colspan="1">99.91%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">72</td><td align="left" rowspan="1" colspan="1">35.89%</td><td align="left" rowspan="1" colspan="1">89.58%</td><td align="left" rowspan="1" colspan="1">99.75%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">13</td><td align="left" rowspan="1" colspan="1">7<sup>c</sup></td><td align="left" rowspan="1" colspan="1">72</td><td align="left" rowspan="1" colspan="1">28.40%</td><td align="left" rowspan="1" colspan="1">80.03%</td><td align="left" rowspan="1" colspan="1">98.68%</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">24</td><td align="left" rowspan="1" colspan="1">84</td><td align="left" rowspan="1" colspan="1">41.34%</td><td align="left" rowspan="1" colspan="1">93.76%</td><td align="left" rowspan="1" colspan="1">99.93%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">84</td><td align="left" rowspan="1" colspan="1">36.07%</td><td align="left" rowspan="1" colspan="1">89.70%</td><td align="left" rowspan="1" colspan="1">99.76%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">13</td><td align="left" rowspan="1" colspan="1">6<sup>d</sup></td><td align="left" rowspan="1" colspan="1">84</td><td align="left" rowspan="1" colspan="1">26.20%</td><td align="left" rowspan="1" colspan="1">76.03%</td><td align="left" rowspan="1" colspan="1">97.87%</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>The variability of the responses is fixed at 2.25. Three strategies for selecting the size of the control group were considered: (i) Optimal, according to the theoretical derivation, (ii) Equal to the treatment groups and (iii) Less than, where the control group replication is less than the treatment groups.</p></fn><fn id="nt102"><label>&#x02020;</label><p>: for control group replication strategy (i) <inline-formula><inline-graphic xlink:href="pone.0114872.e039.jpg"/></inline-formula> is approximately <inline-formula><inline-graphic xlink:href="pone.0114872.e040.jpg"/></inline-formula>, (ii) <inline-formula><inline-graphic xlink:href="pone.0114872.e041.jpg"/></inline-formula> and (iii) <inline-formula><inline-graphic xlink:href="pone.0114872.e042.jpg"/></inline-formula>,</p></fn><fn id="nt103"><label/><p>specifically: a: <inline-formula><inline-graphic xlink:href="pone.0114872.e043.jpg"/></inline-formula>, b: <inline-formula><inline-graphic xlink:href="pone.0114872.e044.jpg"/></inline-formula>, c: <inline-formula><inline-graphic xlink:href="pone.0114872.e045.jpg"/></inline-formula> and d: <inline-formula><inline-graphic xlink:href="pone.0114872.e046.jpg"/></inline-formula>.</p></fn></table-wrap-foot></table-wrap><table-wrap id="pone-0114872-t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0114872.t002</object-id><label>Table 2</label><caption><title>Statistical power of various levels of replication of the control group as the variance increases.</title></caption><alternatives><graphic id="pone-0114872-t002-2" xlink:href="pone.0114872.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Number of treatment groups</td><td align="left" rowspan="1" colspan="1">Control Group Replication Strategy<xref ref-type="table-fn" rid="nt105">&#x02020;</xref></td><td align="left" rowspan="1" colspan="1">Treatment group replication</td><td align="left" rowspan="1" colspan="1">Control group replication</td><td align="left" rowspan="1" colspan="1">Total number of animals</td><td colspan="3" align="left" rowspan="1">Variability of the responses (Variance, Cohen's <italic>d</italic>)</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="pone.0114872.e047.jpg"/></inline-formula></td><td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="pone.0114872.e048.jpg"/></inline-formula></td><td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="pone.0114872.e049.jpg"/></inline-formula></td><td align="left" rowspan="1" colspan="1">(2, 1.41)</td><td align="left" rowspan="1" colspan="1">(4,1)</td><td align="left" rowspan="1" colspan="1">(9, 0.67)</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">74.83%</td><td align="left" rowspan="1" colspan="1">45.15%</td><td align="left" rowspan="1" colspan="1">22.47%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">71.85%</td><td align="left" rowspan="1" colspan="1">42.59%</td><td align="left" rowspan="1" colspan="1">21.21%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">4<sup>a</sup></td><td align="left" rowspan="1" colspan="1">28</td><td align="left" rowspan="1" colspan="1">59.76%</td><td align="left" rowspan="1" colspan="1">33.67%</td><td align="left" rowspan="1" colspan="1">17.05%</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">69.85%</td><td align="left" rowspan="1" colspan="1">41.00%</td><td align="left" rowspan="1" colspan="1">20.47%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">65.16%</td><td align="left" rowspan="1" colspan="1">37.45%</td><td align="left" rowspan="1" colspan="1">18.80%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">2<sup>b</sup></td><td align="left" rowspan="1" colspan="1">30</td><td align="left" rowspan="1" colspan="1">38.64%</td><td align="left" rowspan="1" colspan="1">21.31%</td><td align="left" rowspan="1" colspan="1">11.60%</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">22</td><td align="left" rowspan="1" colspan="1">72</td><td align="left" rowspan="1" colspan="1">95.42%</td><td align="left" rowspan="1" colspan="1">73.33%</td><td align="left" rowspan="1" colspan="1">40.24%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">72</td><td align="left" rowspan="1" colspan="1">92.66%</td><td align="left" rowspan="1" colspan="1">67.42%</td><td align="left" rowspan="1" colspan="1">35.89%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">13</td><td align="left" rowspan="1" colspan="1">7<sup>c</sup></td><td align="left" rowspan="1" colspan="1">72</td><td align="left" rowspan="1" colspan="1">84.44%</td><td align="left" rowspan="1" colspan="1">55.43%</td><td align="left" rowspan="1" colspan="1">28.40%</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">(i)</td><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">24</td><td align="left" rowspan="1" colspan="1">84</td><td align="left" rowspan="1" colspan="1">95.94%</td><td align="left" rowspan="1" colspan="1">74.63%</td><td align="left" rowspan="1" colspan="1">41.34%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(ii)</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">84</td><td align="left" rowspan="1" colspan="1">92.76%</td><td align="left" rowspan="1" colspan="1">67.61%</td><td align="left" rowspan="1" colspan="1">36.07%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">(iii)</td><td align="left" rowspan="1" colspan="1">13</td><td align="left" rowspan="1" colspan="1">6<sup>d</sup></td><td align="left" rowspan="1" colspan="1">84</td><td align="left" rowspan="1" colspan="1">80.77%</td><td align="left" rowspan="1" colspan="1">51.40%</td><td align="left" rowspan="1" colspan="1">26.20%</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt104"><label/><p>The difference between the treatment and control groups is fixed at 2. Three strategies for selecting the size of the control group were considered: (i) Optimal, according to the theoretical derivation, (ii) Equal to the treatment groups and (iii) Less than, where the control group replication is less than the treatment groups.</p></fn><fn id="nt105"><label>&#x02020;</label><p>: for control group replication strategy (i) <inline-formula><inline-graphic xlink:href="pone.0114872.e050.jpg"/></inline-formula> is approximately <inline-formula><inline-graphic xlink:href="pone.0114872.e051.jpg"/></inline-formula>, (ii) <inline-formula><inline-graphic xlink:href="pone.0114872.e052.jpg"/></inline-formula> and (iii) <inline-formula><inline-graphic xlink:href="pone.0114872.e053.jpg"/></inline-formula>,</p></fn><fn id="nt106"><label/><p>specifically: a: <inline-formula><inline-graphic xlink:href="pone.0114872.e054.jpg"/></inline-formula>, b: <inline-formula><inline-graphic xlink:href="pone.0114872.e055.jpg"/></inline-formula>, c: <inline-formula><inline-graphic xlink:href="pone.0114872.e056.jpg"/></inline-formula> and d: <inline-formula><inline-graphic xlink:href="pone.0114872.e057.jpg"/></inline-formula>.</p></fn></table-wrap-foot></table-wrap><p>From <xref ref-type="table" rid="pone-0114872-t001">Tables 1</xref> and <xref ref-type="table" rid="pone-0114872-t002">2</xref> it can be seen that, in the situations considered, a gain in statistical power of between 0.16% and 7.02% (with a median of 3.12%) can be achieved when using the mathematically optimal replication of controls, compared to replicating all groups equally. This benefit is reduced if the statistical power obtained when using both designs approaches 100%. While such improvements are perhaps of marginal practical importance, especially in suitably powered experiments, it is still the case that a slight change to the experimental design can result in more sensitive statistical tests without increasing the total number of animals used.</p><p>Perhaps more strikingly, from <xref ref-type="table" rid="pone-0114872-t001">Table 1</xref> and <xref ref-type="table" rid="pone-0114872-t002">2</xref> it can be seen that there is a significant drop in statistical power if the number of animals in the control group is less than the number in the treatment groups. For example, if a design is required to compare four treatments with a control, the size of biologically relevant effect is 2 and the variability of the responses is 2.25, then a 30% increase in power can be achieved if the optimal replication of animals is used, when compared to a design where there are fewer animals in the control group compared to the treated groups.</p></sec></sec><sec id="s4"><title>Conclusions</title><p>A review of the literature seems to imply the researcher should use a balanced design with the same number of animals allocated to each experimental group. For example, Ruxton and Colegrave <xref rid="pone.0114872-Ruxton1" ref-type="bibr">[19]</xref> state &#x0201c;Always aim to balance your experiment, unless you have a very good reason not to&#x0201d;. In many statistical texts the sample size calculation is performed when the experimental design consists of only two groups. In this case the balanced design is usually a sensible choice. Unfortunately designs used in practice are rarely so straightforward, and hence the orthodox strategy may not always be appropriate.</p><p>In this paper we have shown the benefit that can be gained from using an experimental design that has been constructed to favour the comparisons that the researcher plans to make. Focusing on the comparisons of interest increases sensitivity as it reduces the adjustment that is required to manage the multiple testing burden (i.e. reduce the false positive risk). In the case considered in this paper, where the researcher wishes to compare <italic>t</italic> treatments to a control, the design should be selected so that the number of animals in the control group is <inline-formula><inline-graphic xlink:href="pone.0114872.e058.jpg"/></inline-formula> times the number in the treated groups. It has been shown that such a design performs better than the commonly used strategy of equally replicating across the treatment and control groups. While beyond the scope of this paper, a similar approach can be used for the more complicated experimental designs. For example, the choice of block or cross-over design can influence the reliability of the treatment comparisons.</p><p>Another strategy that researchers may follow when designing their experiments is to reduce the number of animals in the control group compared to the treatment groups. This approach is usually taken because the researcher has access to historical control data and feels that this knowledge implies fewer concurrent controls are needed. There has been much written about the benefit of using historical control data when assessing the effect of treatments <xref rid="pone.0114872-Greim1" ref-type="bibr">[20]</xref> though it does not replace concurrent controls. Prior knowledge, perhaps obtained from a historical control database, can also be incorporated into the statistical analysis using a Bayesian analysis paradigm. This approach has been successfully applied in clinical research, although such studies usually involve comparing a single treatment to a control or placebo <xref rid="pone.0114872-Viele1" ref-type="bibr">[21]</xref>. While there are certain benefits to comparing multiple treatments to a historical control group, this work highlights that a study with both concurrent and historic controls does not necessarily imply that fewer animals can be included in a concurrent control. When treatments are compared using the popular statistical analysis approaches discussed in the methods section, we have demonstrated that having more animals in the treatment groups, compared to the control group, can lead to a significant reduction in statistical power regardless of the benefits of using historical control information.</p><p>In this paper we have assumed that the variability is the same in all experimental groups. In practice this assumption may not hold. For example, in biological responses it is common for the variability to increase with the size of the response. Furthermore, responses that are bounded (e.g. percentages which cannot go below 0 or above 100) tend to be less variable as a boundary is approached. In such cases, there are statistical analysis strategies that can be applied, but they are beyond the scope of this paper. An alternative strategy, commonly recommended <xref rid="pone.0114872-Bate1" ref-type="bibr">[8]</xref>, <xref rid="pone.0114872-Snedecor1" ref-type="bibr">[14]</xref>, <xref rid="pone.0114872-Zar1" ref-type="bibr">[22]</xref>, is to investigate the use of non-linear data transformations to &#x0201c;correct&#x0201d; the data which then allow application of the methods discussed within this paper. For example, the arcsine transformation for percentage data, square root transformation for count data and log transformation if the variability increases as the response increases.</p><p>The arguments presented in this paper, also assume that any attrition due to experimental procedures is expected to be the same across all groups. If the researcher believes, for example, that they are likely to lose more animals in the treated groups, then they may wish to adjust the initial sample sizes so that the sample sizes achieved at the end of the study should result in a design that is close to the optimal design.</p><p>In practice, if the experiment is to be successful, many considerations should be taken into account when constructing a design. Issues such as practical constraints on the experimental material, financial pressures and ethical issues should be taken into account alongside optimal statistical design theory. In this paper we have aimed to highlight what a theoretically optimal experimental design, all things being equal, would be. The researcher should use this knowledge, in conjunction with other constraints, when planning their experiment.</p></sec><sec sec-type="supplementary-material" id="s5"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0114872.s001"><label>S1 Derivations</label><caption><p>Determining the optimum control group <bold>replication.</bold></p><p>(DOCX)</p></caption><media xlink:href="pone.0114872.s001.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0114872.s002"><label>S2 Derivations</label><caption><p>Determining the statistical power.</p><p>(DOCX)</p></caption><media xlink:href="pone.0114872.s002.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We would like to dedicate this paper to the late Robert Kempson who brought this problem and solution to our attention.</p></ack><ref-list><title>References</title><ref id="pone.0114872-Russell1"><label>1</label><mixed-citation publication-type="other">Russell WMS, Burch RL (1959) The Principles of Humane Experimental Technique. London: Methuen &#x00026; Co. Ltd.</mixed-citation></ref><ref id="pone.0114872-Kilkenny1"><label>2</label><mixed-citation publication-type="journal"><name><surname>Kilkenny</surname><given-names>C</given-names></name>, <name><surname>Parsons</surname><given-names>N</given-names></name>, <name><surname>Kadyszewski</surname><given-names>E</given-names></name>, <name><surname>Festing</surname><given-names>MFW</given-names></name>, <name><surname>Cuthill</surname><given-names>IC</given-names></name>, <etal>et al</etal> (<year>2009</year>) <article-title>Survey of the Quality of Experimental Design, Statistical Analysis and Reporting of Research Using Animals</article-title>. <source>PLoS ONE</source>
<volume>4</volume>(<issue>11</issue>):<fpage>e7824</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0007824">10.1371/journal.pone.0007824</ext-link></comment><pub-id pub-id-type="pmid">19956596</pub-id></mixed-citation></ref><ref id="pone.0114872-Kilkenny2"><label>3</label><mixed-citation publication-type="journal"><name><surname>Kilkenny</surname><given-names>C</given-names></name>, <name><surname>Browne</surname><given-names>WJ</given-names></name>, <name><surname>Cuthill</surname><given-names>IC</given-names></name>, <name><surname>Emerson</surname><given-names>M</given-names></name>, <name><surname>Altman</surname><given-names>DG</given-names></name> (<year>2010</year>) <article-title>Improving Bioscience Research Reporting: The ARRIVE Guidelines for Reporting Animal Research</article-title>. <source>PLoS Biol</source>
<volume>8</volume>(<issue>6</issue>):<fpage>e1000412</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1000412">10.1371/journal.pbio.1000412</ext-link></comment><pub-id pub-id-type="pmid">20613859</pub-id></mixed-citation></ref><ref id="pone.0114872-Perel1"><label>4</label><mixed-citation publication-type="journal"><name><surname>Perel</surname><given-names>P</given-names></name>, <name><surname>Roberts</surname><given-names>I</given-names></name>, <name><surname>Sena</surname><given-names>E</given-names></name>, <name><surname>Wheble</surname><given-names>P</given-names></name>, <name><surname>Briscoe</surname><given-names>C</given-names></name>, <etal>et al</etal> (<year>2007</year>) <article-title>Comparison of treatment effects between animal experiments and clinical trials: systematic review</article-title>. <source>British Medical Journal</source>
<volume>334</volume>:<fpage>197</fpage>&#x02013;<lpage>200</lpage>.<pub-id pub-id-type="pmid">17175568</pub-id></mixed-citation></ref><ref id="pone.0114872-Sun1"><label>5</label><mixed-citation publication-type="journal"><name><surname>Sun</surname><given-names>TT</given-names></name> (<year>2004</year>) <article-title>Excessive trust in authorities and its influence on experimental design</article-title>. <source>Nature Reviews Molecular Cell Biology</source>
<volume>5</volume>:<fpage>577</fpage>&#x02013;<lpage>581</lpage>.</mixed-citation></ref><ref id="pone.0114872-Ioannidis1"><label>6</label><mixed-citation publication-type="journal"><name><surname>Ioannidis</surname><given-names>JPA</given-names></name> (<year>2005</year>) <article-title>Why Most Published Research Findings Are False</article-title>. <source>PLoS Med</source>
<volume>2</volume>(<issue>8</issue>):<fpage>e124</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.0020124">10.1371/journal.pmed.0020124</ext-link></comment><pub-id pub-id-type="pmid">16060722</pub-id></mixed-citation></ref><ref id="pone.0114872-GarcaPrez1"><label>7</label><mixed-citation publication-type="journal"><name><surname>Garc&#x000ed;a-P&#x000e9;rez</surname><given-names>MA</given-names></name> (<year>2012</year>) <article-title>Statistical conclusion validity: some common threats and simple remedies</article-title>. <source>Frontiers in Psychology</source>
<volume>3</volume>:<fpage>325</fpage>.<pub-id pub-id-type="pmid">22952465</pub-id></mixed-citation></ref><ref id="pone.0114872-Bate1"><label>8</label><mixed-citation publication-type="other">Bate ST, Clark RA (2014) The Design and Statistical Analysis of Animal Experiments. Cambridge: Cambridge University Press.</mixed-citation></ref><ref id="pone.0114872-Thomas1"><label>9</label><mixed-citation publication-type="journal"><name><surname>Thomas</surname><given-names>L</given-names></name>, <name><surname>Juanes</surname><given-names>F</given-names></name> (<year>1996</year>) <article-title>The importance of statistical power analysis: An example from Animal Behaviour</article-title>. <source>Animal Behaviour</source>
<volume>52</volume>:<fpage>856</fpage>&#x02013;<lpage>859</lpage>.</mixed-citation></ref><ref id="pone.0114872-Rozza1"><label>10</label><mixed-citation publication-type="journal"><name><surname>Rozza</surname><given-names>AL</given-names></name>, <name><surname>Meira de Faria</surname><given-names>F</given-names></name>, <name><surname>Souza Brito</surname><given-names>AR</given-names></name>, <name><surname>Pellizzon</surname><given-names>CH</given-names></name> (<year>2014</year>) <article-title>The Gastroprotective Effect of Menthol: Involvement of Anti-Apoptotic, Antioxidant and Anti-Inflammatory Activities</article-title>. <source>PLoS ONE</source>
<volume>9</volume>(<issue>1</issue>):<fpage>e86686</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0086686">10.1371/journal.pone.0086686</ext-link></comment><pub-id pub-id-type="pmid">24466200</pub-id></mixed-citation></ref><ref id="pone.0114872-Nekohashi1"><label>11</label><mixed-citation publication-type="journal"><name><surname>Nekohashi</surname><given-names>M</given-names></name>, <name><surname>Ogawa</surname><given-names>M</given-names></name>, <name><surname>Ogihara</surname><given-names>T</given-names></name>, <name><surname>Nakazawa</surname><given-names>K</given-names></name>, <name><surname>Kato</surname><given-names>H</given-names></name>, <etal>et al</etal> (<year>2014</year>) <article-title>Luteolin and Quercetin Affect the Cholesterol Absorption Mediated by Epithelial Cholesterol Transporter Niemann&#x02013;Pick C1-Like 1 in Caco-2 Cells and Rats</article-title>. <source>PLoS ONE</source>
<volume>9</volume>(<issue>5</issue>):<fpage>e97901</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0097901">10.1371/journal.pone.0097901</ext-link></comment><pub-id pub-id-type="pmid">24859282</pub-id></mixed-citation></ref><ref id="pone.0114872-Zhou1"><label>12</label><mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>K</given-names></name>, <name><surname>Jiang</surname><given-names>M</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Qu</surname><given-names>Y</given-names></name>, <name><surname>Shi</surname><given-names>G</given-names></name>, <etal>et al</etal> (<year>2014</year>) <article-title>Effect of Bile Pigments on the Compromised Gut Barrier Function in a Rat Model of Bile Duct Ligation</article-title>. <source>PLoS ONE</source>
<volume>9</volume>(<issue>6</issue>):<fpage>e98905</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0098905">10.1371/journal.pone.0098905</ext-link></comment><pub-id pub-id-type="pmid">24892651</pub-id></mixed-citation></ref><ref id="pone.0114872-Lee1"><label>13</label><mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>S-H</given-names></name>, <name><surname>Kim</surname><given-names>Y</given-names></name>, <name><surname>Kim</surname><given-names>HY</given-names></name>, <name><surname>Kim</surname><given-names>YH</given-names></name>, <name><surname>Kim</surname><given-names>MS</given-names></name>, <etal>et al</etal> (<year>2014</year>) <article-title>Aminostyrylbenzofuran Directly Reduces Oligomeric Amyloid-&#x003b2; and Reverses Cognitive Deficits in Alzheimer Transgenic Mice</article-title>. <source>PLoS ONE</source>
<volume>9</volume>(<issue>4</issue>):<fpage>e95733</fpage>
<comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0095733">10.1371/journal.pone.0095733</ext-link></comment><pub-id pub-id-type="pmid">24760018</pub-id></mixed-citation></ref><ref id="pone.0114872-Snedecor1"><label>14</label><mixed-citation publication-type="other">Snedecor GW, Cochran WG (1989) Statistical Methods, eighth edition. Iowa: Iowa State University Press.</mixed-citation></ref><ref id="pone.0114872-Lenth1"><label>15</label><mixed-citation publication-type="journal"><name><surname>Lenth</surname><given-names>RV</given-names></name> (<year>2001</year>) <article-title>Some practical guidelines for effective sample size determination</article-title>. <source>American Statistician</source>
<volume>55</volume>:<fpage>187</fpage>&#x02013;<lpage>193</lpage>.</mixed-citation></ref><ref id="pone.0114872-Faul1"><label>16</label><mixed-citation publication-type="journal"><name><surname>Faul</surname><given-names>F</given-names></name>, <name><surname>Erdfelder</surname><given-names>E</given-names></name>, <name><surname>Lang</surname><given-names>AG</given-names></name>, <name><surname>Buchner</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title>. <source>Behavior Research Methods</source>
<volume>39</volume>:<fpage>175</fpage>&#x02013;<lpage>191</lpage>.<pub-id pub-id-type="pmid">17695343</pub-id></mixed-citation></ref><ref id="pone.0114872-Clark1"><label>17</label><mixed-citation publication-type="journal"><name><surname>Clark</surname><given-names>RA</given-names></name>, <name><surname>Shoaib</surname><given-names>M</given-names></name>, <name><surname>Hewitt</surname><given-names>KN</given-names></name>, <name><surname>Stanford</surname><given-names>SC</given-names></name>, <name><surname>Bate</surname><given-names>ST</given-names></name> (<year>2012</year>) <article-title>A comparison of InVivoStat with other statistical software packages for analysis of data generated from animal experiments</article-title>. <source>Journal of Psychopharmacology</source>
<volume>26</volume>:<fpage>1136</fpage>&#x02013;<lpage>1142</lpage>.<pub-id pub-id-type="pmid">22071578</pub-id></mixed-citation></ref><ref id="pone.0114872-Cohen1"><label>18</label><mixed-citation publication-type="other">Cohen J (1988) Statistical power analysis for the behavioral sciences, second edition. New Jersey: Erlbaum.</mixed-citation></ref><ref id="pone.0114872-Ruxton1"><label>19</label><mixed-citation publication-type="other">Ruxton GD, Colegrave NC (2006) Experimental Design for the Life Sciences. Oxford: Oxford University Press.</mixed-citation></ref><ref id="pone.0114872-Greim1"><label>20</label><mixed-citation publication-type="journal"><name><surname>Greim</surname><given-names>H</given-names></name>, <name><surname>Gelbke</surname><given-names>HP</given-names></name>, <name><surname>Reuter</surname><given-names>U</given-names></name>, <name><surname>Thielmann</surname><given-names>HW</given-names></name>, <name><surname>Edler</surname><given-names>L</given-names></name> (<year>2003</year>) <article-title>Evaluation of historical control data in carcinogenicity studies</article-title>. <source>Human and Experimental Toxicology</source>
<volume>22</volume>:<fpage>541</fpage>&#x02013;<lpage>549</lpage>.<pub-id pub-id-type="pmid">14655720</pub-id></mixed-citation></ref><ref id="pone.0114872-Viele1"><label>21</label><mixed-citation publication-type="journal"><name><surname>Viele</surname><given-names>K</given-names></name>, <name><surname>Berry</surname><given-names>S</given-names></name>, <name><surname>Neuenschwander</surname><given-names>B</given-names></name>, <name><surname>Amzal</surname><given-names>B</given-names></name>, <name><surname>Chen</surname><given-names>F</given-names></name>, <etal>et al</etal> (<year>2014</year>) <article-title>Use of historical control data for assessing treatment effects in clinical trials</article-title>. <source>Pharmaceutical Statistics</source>
<volume>13</volume>:<fpage>41</fpage>&#x02013;<lpage>54</lpage>.<pub-id pub-id-type="pmid">23913901</pub-id></mixed-citation></ref><ref id="pone.0114872-Zar1"><label>22</label><mixed-citation publication-type="other">Zar JH (1998) Biostatistical Analysis, fourth edition. New Jersey: Prentice Hall.</mixed-citation></ref></ref-list></back></article>